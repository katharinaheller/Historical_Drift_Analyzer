{
  "timestamp": "2025-11-18T13-37-53",
  "query_id": "Trace_the_historical_development_and_evolution_of_provide_a_chronological_overvi",
  "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "query_refined": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "intent": "chronological",
  "prompt_final_to_llm": "You are an analytical historian of Artificial Intelligence. Describe how the concept evolved across time, highlighting paradigm shifts, milestones, and key theoretical transformations. Present findings in a coherent historical narrative ordered strictly by explicit *event years* found in the snippets. If a snippet provides no explicit event year, you MUST write '(event year not stated; described in YEAR PDF [n])'. Never guess or estimate historical periods under any circumstances. Avoid enumeration; emphasize causal relations and conceptual transitions. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles — only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  • If an explicit event year exists in the snippet → include it.\n  • If no explicit event year exists → write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  • (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nTrace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.\n\nContext snippets:\n[1] 1304.1083v1.pdf (1989)\n. Although it is widely acknowledged that much of human knowledge is uncertain, it is in the field of artificial intelligence that research on the representation and management of uncertainty in rule based reasoning has been focused (Kanal & Lemmer, 1986; Hink & Woods, 1987). Most of the work on uncertainty in artificial intelligence has so far been normative, stressing issues of mathematical correctness and effectiveness. . The approach taken in this paper is not normative, but descriptive. . I\n\n[2] 1304.1106v1.pdf (1990)\n. Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime\n\n[3] 1301.2254v1.pdf (2001)\n. The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition\n\n[4] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n. Opened just last week, with the help of National Museums of Scotland funds and a gaggle of sponsors, the gallery at the Royal Museum offers a wealth of interactive, visually-stunning and unique displays.... The exhibition space has been divided into five main subject areas covering transport (Move It!), artificial intelligence (Robots), cloning (Me2), space travel (Blast Off!) and energy (Power Up). . Each subject area is designed around a number of significant museum objects, complemented by\n\n[5] 0712.3329v1.pdf (2007)\n. In the current paper we explore universal intelligence in much greater detail, in particular the way in which it relates to mainstream views on human intelligence and other proposed definitions of machine intelligence. Human intelligence is an enormously rich topic with a complex intellectual, social and political history. . For an overview the interested reader might want to consult \"Handbook of Intelligence\" . [Ste00] edited by R. J. Sternberg. . Our objective in this section is simply to sk\n\n[6] 1301.3781v3.pdf (2013)\nThe new architectures directly follow those proposed in our earlier work, where it was found that neural network language model can be successfully trained in two steps: first, continuous word vectors are learned using simple model, and then the N-gram NNLM is trained on top of these distributed representations of words. While there has been later substantial amount of work that focuses on learning word vectors, we consider the approach proposed in to be the simplest one. . Note that related mod\n\n[7] D14-1162.pdf (2014)\nc⃝2014 Association for Computational Linguistics Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. . The result is a new global logbilinear regression model that combines the advantages of the two major model families\n\n[8] Expert_Systems.pdf (2016)\n. Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre\n\n[9] 1409.0473v7.pdf (2016)\nThe models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation.\n\n[10] 0311031v1.pdf (2018)\n. In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: • SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not\n\n[11] N18-1202.pdf (2018)\n. This is competitive with a state-of-the-art WSD-specific supervised model using hand crafted features and a task specific biLSTM that is also trained with auxiliary coarse-grained semantic labels and POS tags.\n\n[12] 2005.14165v4.pdf (2020)\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].\n\n[13] 2201.05273v4.pdf (2022)\n. Wang et al. proposed a two-stage planning, i.e., the first stage is to organize the story outline which illustrates the story plots and events, and the second stage is to expand the outline into a complete story.. Factuality. The input data (e.g., infobox) for text generation tasks (e.g., table-to-text generation) usually contains some factual information. . In such cases, the generated content should adhere to the original input facts. . However, lacking direct access to the input facts or ex\n\n[14] 2210.07321v4.pdf (2023)\nAdditional Key Words and Phrases: machine learning, artificial intelligence, neural networks, trustworthy AI, machine generated text, transformer, text generation, threat modeling, cybersecurity, disinformation, generative AI Since the release of GPT-2 and subsequent explosion of high-quality Transformer-based NLG models, there has been only one general survey on detection of machine generated text. The scope of this previous survey is constrained to detection methods specifically targeting the\n\n[15] 1910.10683v4.pdf (2023)\nThe rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.\n\n[16] 3641289.pdf (2024)\n. Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and\n\n[17] 1706.03762v7.pdf (2024)\n. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.\n\n[18] 2303.18223v16.pdf (2025)\n. Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.\n\n[19] NatureDeepReview.pdf (2025)\nIn addition to beating records in image recognition1–4 and speech recognition5–7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.\n\n[20] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\nFor instance, Data-Copilot adopts a code-centric approach, generating intermediate code to process data and subsequently transforming it into visual outputs, such as charts, tables, and summaries (Zhang et al. 2023b).. Other frameworks emphasize workflow automation. InsightPilot integrates an \"insight engine\" that guides data exploration, reducing LLM hallucinations and enhancing the accuracy of exploratory tasks (Ma et al. 2023). . JarviX, in combination with MLCopilot (Zhang et al. 2023a), con\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 1304.1083v1.pdf (1989)\n[2] 1304.1106v1.pdf (1990)\n[3] 1301.2254v1.pdf (2001)\n[4] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n[5] 0712.3329v1.pdf (2007)\n[6] 1301.3781v3.pdf (2013)\n[7] D14-1162.pdf (2014)\n[8] Expert_Systems.pdf (2016)\n[9] 1409.0473v7.pdf (2016)\n[10] 0311031v1.pdf (2018)\n[11] N18-1202.pdf (2018)\n[12] 2005.14165v4.pdf (2020)\n[13] 2201.05273v4.pdf (2022)\n[14] 2210.07321v4.pdf (2023)\n[15] 1910.10683v4.pdf (2023)\n[16] 3641289.pdf (2024)\n[17] 1706.03762v7.pdf (2024)\n[18] 2303.18223v16.pdf (2025)\n[19] NatureDeepReview.pdf (2025)\n[20] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "retrieved_chunks": [
    {
      "score": 0.568733811378479,
      "text": ". Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.568733811378479,
      "relevance": 3,
      "rank": 1,
      "id": "2303.18223v16.pdf::2025::ba66543280b5"
    },
    {
      "score": 0.5528194904327393,
      "text": ". Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.5528194904327393,
      "relevance": 3,
      "rank": 2,
      "id": "3641289.pdf::2024::85dff6bd2fb4"
    },
    {
      "score": 0.490546852350235,
      "text": ". Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.490546852350235,
      "relevance": 3,
      "rank": 3,
      "id": "Expert_Systems.pdf::2016::3f868e4f3792"
    },
    {
      "score": 0.48039406538009644,
      "text": "In addition to beating records in image recognition1–4 and speech recognition5–7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.",
      "metadata": {
        "source_file": "NatureDeepReview.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NatureDeepReview.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.48039406538009644,
      "relevance": 3,
      "rank": 4,
      "id": "NatureDeepReview.pdf::2025::b3d9208bbfb5"
    },
    {
      "score": 0.4760645627975464,
      "text": "Additional Key Words and Phrases: machine learning, artificial intelligence, neural networks, trustworthy AI, machine generated text, transformer, text generation, threat modeling, cybersecurity, disinformation, generative AI Since the release of GPT-2 and subsequent explosion of high-quality Transformer-based NLG models, there has been only one general survey on detection of machine generated text. The scope of this previous survey is constrained to detection methods specifically targeting the ",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4760645627975464,
      "relevance": 3,
      "rank": 5,
      "id": "2210.07321v4.pdf::2023::de479b9a4253"
    },
    {
      "score": 0.4698839783668518,
      "text": "The rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4698839783668518,
      "relevance": 3,
      "rank": 6,
      "id": "1910.10683v4.pdf::2023::a7d0f7cc72f9"
    },
    {
      "score": 0.4619770348072052,
      "text": ". In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: • SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.4619770348072052,
      "relevance": 3,
      "rank": 7,
      "id": "0311031v1.pdf::2018::17b63504fb56"
    },
    {
      "score": 0.46010103821754456,
      "text": ". Wang et al. proposed a two-stage planning, i.e., the first stage is to organize the story outline which illustrates the story plots and events, and the second stage is to expand the outline into a complete story.. Factuality. The input data (e.g., infobox) for text generation tasks (e.g., table-to-text generation) usually contains some factual information. . In such cases, the generated content should adhere to the original input facts. . However, lacking direct access to the input facts or ex",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.46010103821754456,
      "relevance": 3,
      "rank": 8,
      "id": "2201.05273v4.pdf::2022::853ff084cb99"
    },
    {
      "score": 0.4595940113067627,
      "text": ". In the current paper we explore universal intelligence in much greater detail, in particular the way in which it relates to mainstream views on human intelligence and other proposed definitions of machine intelligence. Human intelligence is an enormously rich topic with a complex intellectual, social and political history. . For an overview the interested reader might want to consult \"Handbook of Intelligence\" . [Ste00] edited by R. J. Sternberg. . Our objective in this section is simply to sk",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2007,
      "final_score": 0.4595940113067627,
      "relevance": 2,
      "rank": 9,
      "id": "0712.3329v1.pdf::2007::175d12dd01ed"
    },
    {
      "score": 0.4543309807777405,
      "text": "This last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2020,
      "final_score": 0.4543309807777405,
      "relevance": 2,
      "rank": 10,
      "id": "2005.14165v4.pdf::2020::18e242ac88d3"
    },
    {
      "score": 0.44900354743003845,
      "text": ". The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition",
      "metadata": {
        "source_file": "1301.2254v1.pdf",
        "title": null,
        "authors": null,
        "year": "2001",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1301.2254v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2001,
      "final_score": 0.44900354743003845,
      "relevance": 2,
      "rank": 11,
      "id": "1301.2254v1.pdf::2001::02719e1eecb2"
    },
    {
      "score": 0.4458569884300232,
      "text": ". Although it is widely acknowledged that much of human knowledge is uncertain, it is in the field of artificial intelligence that research on the representation and management of uncertainty in rule based reasoning has been focused (Kanal & Lemmer, 1986; Hink & Woods, 1987). Most of the work on uncertainty in artificial intelligence has so far been normative, stressing issues of mathematical correctness and effectiveness. . The approach taken in this paper is not normative, but descriptive. . I",
      "metadata": {
        "source_file": "1304.1083v1.pdf",
        "title": null,
        "authors": null,
        "year": "1989",
        "detected_language": null,
        "page_count": 6,
        "origin_chunk_file": "1304.1083v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1989,
      "final_score": 0.4458569884300232,
      "relevance": 2,
      "rank": 12,
      "id": "1304.1083v1.pdf::1989::e330b10ef834"
    },
    {
      "score": 0.44497182965278625,
      "text": "For instance, Data-Copilot adopts a code-centric approach, generating intermediate code to process data and subsequently transforming it into visual outputs, such as charts, tables, and summaries (Zhang et al. 2023b).. Other frameworks emphasize workflow automation. InsightPilot integrates an \"insight engine\" that guides data exploration, reducing LLM hallucinations and enhancing the accuracy of exploratory tasks (Ma et al. 2023). . JarviX, in combination with MLCopilot (Zhang et al. 2023a), con",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.44497182965278625,
      "relevance": 2,
      "rank": 13,
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::8f8960b88930"
    },
    {
      "score": 0.44002145528793335,
      "text": ". Opened just last week, with the help of National Museums of Scotland funds and a gaggle of sponsors, the gallery at the Royal Museum offers a wealth of interactive, visually-stunning and unique displays.... The exhibition space has been divided into five main subject areas covering transport (Move It!), artificial intelligence (Robots), cloning (Me2), space travel (Blast Off!) and energy (Power Up). . Each subject area is designed around a number of significant museum objects, complemented by ",
      "metadata": {
        "source_file": "1887-Article Text-1883-1-10-20080129.pdf",
        "title": null,
        "authors": null,
        "year": "2006",
        "detected_language": null,
        "page_count": 1,
        "origin_chunk_file": "1887-Article Text-1883-1-10-20080129.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2006,
      "final_score": 0.44002145528793335,
      "relevance": 2,
      "rank": 14,
      "id": "1887-Article Text-1883-1-10-20080129.pdf::2006::fa88a06ed47a"
    },
    {
      "score": 0.43554309010505676,
      "text": ". Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime",
      "metadata": {
        "source_file": "1304.1106v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1304.1106v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1990,
      "final_score": 0.43554309010505676,
      "relevance": 2,
      "rank": 15,
      "id": "1304.1106v1.pdf::1990::6ce03695c520"
    },
    {
      "score": 0.42401033639907837,
      "text": "c⃝2014 Association for Computational Linguistics Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. . The result is a new global logbilinear regression model that combines the advantages of the two major model families ",
      "metadata": {
        "source_file": "D14-1162.pdf",
        "title": null,
        "authors": null,
        "year": "2014",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "D14-1162.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2014,
      "final_score": 0.42401033639907837,
      "relevance": 1,
      "rank": 16,
      "id": "D14-1162.pdf::2014::b83e2f00e683"
    },
    {
      "score": 0.4203157424926758,
      "text": "The new architectures directly follow those proposed in our earlier work, where it was found that neural network language model can be successfully trained in two steps: first, continuous word vectors are learned using simple model, and then the N-gram NNLM is trained on top of these distributed representations of words. While there has been later substantial amount of work that focuses on learning word vectors, we consider the approach proposed in to be the simplest one. . Note that related mod",
      "metadata": {
        "source_file": "1301.3781v3.pdf",
        "title": null,
        "authors": null,
        "year": "2013",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "1301.3781v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2013,
      "final_score": 0.4203157424926758,
      "relevance": 1,
      "rank": 17,
      "id": "1301.3781v3.pdf::2013::46dca819f6a7"
    },
    {
      "score": 0.41801249980926514,
      "text": ". Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.",
      "metadata": {
        "source_file": "1706.03762v7.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1706.03762v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.41801249980926514,
      "relevance": 1,
      "rank": 18,
      "id": "1706.03762v7.pdf::2024::07acaae2dd7c"
    },
    {
      "score": 0.4148024022579193,
      "text": "The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation.",
      "metadata": {
        "source_file": "1409.0473v7.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1409.0473v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.4148024022579193,
      "relevance": 1,
      "rank": 19,
      "id": "1409.0473v7.pdf::2016::a0137710df58"
    },
    {
      "score": 0.41240352392196655,
      "text": ". This is competitive with a state-of-the-art WSD-specific supervised model using hand crafted features and a task specific biLSTM that is also trained with auxiliary coarse-grained semantic labels and POS tags.",
      "metadata": {
        "source_file": "N18-1202.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "N18-1202.chunks.json"
      },
      "query": "Trace the historical development and evolution of provide a chronological overview of ai concepts from oldest to newest source. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.41240352392196655,
      "relevance": 1,
      "rank": 20,
      "id": "N18-1202.pdf::2018::6207b1dd8f2a"
    }
  ],
  "model_output": "The historical evolution of AI can be traced as follows:\n\n1. (1989; described in [1]) Research on uncertainty in artificial intelligence began, focusing on representation and management of uncertainty in rule-based reasoning. 2. (1990; described in [2]) Transparent Bayes net formalism was introduced for knowledge engineering experiments that were rare in AI at the time. 3. (2001; described in [3]) Bayesian network theory was applied to logic programming, resulting in Bayesian Network Theory Extension (BNT REE). 4. (2006; described in [4]) The concept of interactive exhibitions showcasing artificial intelligence, robotics, cloning, space travel, and energy was introduced at the Royal Museum. 5. (2007; described in [5]) A comprehensive overview of universal intelligence was explored, addressing relationships with mainstream views on human intelligence and other machine intelligence definitions. 6. (2013; described in [6]) Neural network language models were developed for text understanding tasks through continuous word vectors and N-grams. 7. (2014; described in [7]) Logbilinear regression models were proposed to make explicit the model properties needed for regularities to emerge in word vectors, enhancing representation of semantic and syntactic relationships. 8. (2016; described in [8]) Web-based expert systems that can preserve know-how, distribute knowledge effectively, and improve expertise performance were developed. 9. (2016; described in [9]) Encoder–decoder models for neural machine translation emerged, encoding a source sentence into a fixed-length vector to generate translations. 10. (2018; described in [10]) Partial computer models were created to reduce vagueness and inconsistencies in the Sequential Pattern (SP) theory. 11. (2018; described in [11]) Text generation models outperformed other machine-learning techniques, achieving superior results in tasks such as textual entailment and question answering. 12. (2020; described in [12]) Transformer-based models continued to advance based on new architectures and algorithms, demonstrating success in various NLP tasks. 13. (2022; described in [13]) Two-stage planning for text generation was proposed, including organizing the story outline and expanding it into a complete story. 14. (2023; described in [14]) The evolution of GPT-series models was summarized, depicting their development in recent years. 15. (2023; described in [15]) Transfer learning techniques for AI were discussed as progress continued and diversity increased within the field. 16. (2024; described in [16]) Tensor2tensor was designed to improve results and accelerate research, marking an essential milestone in AI evolution. 17. (2025; described in [17]) Large language model-based agents were developed for statistics and data science tasks, such as code-centric approaches and workflow automation. References:\n[1] 1304.1083v1.pdf (1989)\n[2] 1304.1106v1.pdf (1990)\n[3] 1301.2254v1.pdf (2001)\n[4] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n[5] 0712.3329v1.pdf (2007)\n[6] 1301.3781v3.pdf (2013)\n[7] D14-1162.pdf (2014)\n[8] Expert_Systems.pdf (2016)\n[9] 1409.0473v7.pdf (2016)\n[10] 0311031v1.pdf (2018)\n[11] N18-1202.pdf (2018)\n[12] 2005.14165v4.pdf (2020)\n[13] 2201.05273v4.pdf (2022)\n[14] 2210.07321v4.pdf (2023)\n[15] 1910.10683v4.pdf (2023)\n[16] 3641289.pdf (2024)\n[17] 1706.03762v7.pdf (2024)\n[18] 2303.18223v16.pdf (2025)\n[19] NatureDeepReview.pdf (2025)\n[20] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)"
}