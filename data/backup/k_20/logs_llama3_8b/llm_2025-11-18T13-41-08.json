{
  "timestamp": "2025-11-18T13-41-08",
  "query_id": "Trace_the_historical_development_and_evolution_of_outline_how_ai_research_priori",
  "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "query_refined": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "intent": "chronological",
  "prompt_final_to_llm": "You are an analytical historian of Artificial Intelligence. Describe how the concept evolved across time, highlighting paradigm shifts, milestones, and key theoretical transformations. Present findings in a coherent historical narrative ordered strictly by explicit *event years* found in the snippets. If a snippet provides no explicit event year, you MUST write '(event year not stated; described in YEAR PDF [n])'. Never guess or estimate historical periods under any circumstances. Avoid enumeration; emphasize causal relations and conceptual transitions. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles — only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  • If an explicit event year exists in the snippet → include it.\n  • If no explicit event year exists → write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  • (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nTrace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.\n\nContext snippets:\n[1] 1304.1083v1.pdf (1989)\nIn each item, the subject was asked to rate the certainty of event X happening by placing a slash on a 16 em line with certain not to happen anchoring the left end, certain to happen anchoring the right end, and uncertain labelling the midpoint Across the 12 rule items there was systematic variation in the type of connective for the antecedents (conjunctive vs. disjunctive) and the certainty and direction of the conclusion (highly vs. moderately certain to happen vs. not-happen).\n\n[2] 1301.2254v1.pdf (2001)\n. The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition\n\n[3] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n. Opened just last week, with the help of National Museums of Scotland funds and a gaggle of sponsors, the gallery at the Royal Museum offers a wealth of interactive, visually-stunning and unique displays.... The exhibition space has been divided into five main subject areas covering transport (Move It!), artificial intelligence (Robots), cloning (Me2), space travel (Blast Off!) and energy (Power Up). . Each subject area is designed around a number of significant museum objects, complemented by\n\n[4] 0712.3329v1.pdf (2007)\n. In the current paper we explore universal intelligence in much greater detail, in particular the way in which it relates to mainstream views on human intelligence and other proposed definitions of machine intelligence. Human intelligence is an enormously rich topic with a complex intellectual, social and political history. . For an overview the interested reader might want to consult \"Handbook of Intelligence\" . [Ste00] edited by R. J. Sternberg. . Our objective in this section is simply to sk\n\n[5] 1301.3781v3.pdf (2013)\n. Furthermore, we also use words from the future; we have obtained the best performance on the task introduced in the next section by building a log-linear classifier with four future and four history words at the input, where the training criterion is to correctly classify the current (middle) word. Training complexity is then Q = N × D + D × log2(V ). . (4) We denote this model further as CBOW, as unlike standard bag-of-words model, it uses continuous distributed representation of the context.\n\n[6] Expert_Systems.pdf (2016)\n. Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre\n\n[7] 0311031v1.pdf (2018)\n. Although more work is required in understanding how the model may be developed for learning, other aspects are sufficiently robust and mature for development into an industrial strength working system.. I am grateful to Thomas Connolly for constructive comments on this article. The responsibility for all errors and oversights is, of course, my own. . M. Abdelguerfiand S. Lavington, editors. . Emerging Trends in Database and Knowledge-base Machines: The Application of Parallel Architectures to\n\n[8] N18-1202.pdf (2018)\n. Our baseline, the ESIM sequence model from Chen et al., uses a biLSTM to encode the premise and hypothesis, followed by a matrix attention layer, a local inference layer, another biLSTM inference composition layer, and finally a pooling operation before the output layer. Overall, adding ELMo to the ESIM model improves accuracy by an average of 0.7% across five random seeds. . A five member ensemble pushes the overall accuracy to 89.3%, exceeding the previous ensemble best of 88.9%. . Semantic\n\n[9] 1810.04805v2.pdf (2019)\n. To train sentence representations, prior work has used objectives to rank candidate next sentences (Jernite et al., 2017; Logeswaran and Lee, 2018), left-to-right generation of next sentence words given a representation of the previous sentence, or denoising autoencoder derived objectives. ELMo and its predecessor (Peters et al., 2017, 2018a) generalize traditional word embedding research along a different dimension. . They extract context-sensitive features from a left-to-right and a right-to\n\n[10] 2005.14165v4.pdf (2020)\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].\n\n[11] 2201.05273v4.pdf (2022)\n. Wang et al. proposed a two-stage planning, i.e., the first stage is to organize the story outline which illustrates the story plots and events, and the second stage is to expand the outline into a complete story.. Factuality. The input data (e.g., infobox) for text generation tasks (e.g., table-to-text generation) usually contains some factual information. . In such cases, the generated content should adhere to the original input facts. . However, lacking direct access to the input facts or ex\n\n[12] 2205.01068v4.pdf (2022)\n. While this is a significant achievement, the energy cost of creating such a model is still nontrivial, and repeated efforts to replicate a model of this size will only amplify the growing compute footprint of these LLMs. We believe the entire AI community — academic researchers, civil society, policymakers, and industry — must work together to develop clear 125M 6.0e−4 0.5M 350M 3.0e−4 0.5M 1.3B . 2.0e−4 1M 2.7B 1.6e−4 1M 6.7B . 1.2e−4 2M 13B 1.0e−4 4M 30B 1.0e−4 4M 66B 0.8e−4 2M 175B 1.2e−4 2\n\n[13] 1910.10683v4.pdf (2023)\nThe rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.\n\n[14] 2210.07321v4.pdf (2023)\n. To summarize, the major contributions of this work are as follows: • The most complete survey of machine generated text detection to date, including previously omitted feature-based work and findings from recent contemporary research.. • The first detailed review of the threat models enabled by machine generated text, at a critical juncture where NLG models and tools are rapidly improving and proliferating. . • . A meaningful exploration of both topics through the lens of Trustworthy AI (TAI),\n\n[15] 3641289.pdf (2024)\n. Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and\n\n[16] 1706.03762v7.pdf (2024)\n. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.\n\n[17] 2303.18223v16.pdf (2025)\n. Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.\n\n[18] NatureDeepReview.pdf (2025)\n. Although deep learning and simple reasoning have been used for speech and handwriting recognition for a long time, new paradigms are needed to replace rule-based manipulation of symbolic expressions by operations on large vectors101.. ■ Figure 5 | A recurrent neural network and the unfolding in time of the computation involved in its forward computation.\n\n[19] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\nWe explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention. Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in realworld scenarios. . Finally, we identify key challenges and propose future res\n\n[20] tanappli2016.pdf (2025)\nTHE APPLICATION OF EXPERT SYSTEM: A REVIEW OF RESEARCH AND APPLICATIONS C. F. Tan1, L. S. Wahidin1, S. N. Khalil1, N. Tamaldin1, J. Hu2 and G.W. M. Rauterberg2 1Integrated Design Research Group, Centre for Advanced Research on Energy, Universiti Teknikal Malaysia Melaka, Durian Tunggal, Melaka, Malaysia 2Designed Intelligence Group, Department of Industrial Design, Eindhoven\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 1304.1083v1.pdf (1989)\n[2] 1301.2254v1.pdf (2001)\n[3] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n[4] 0712.3329v1.pdf (2007)\n[5] 1301.3781v3.pdf (2013)\n[6] Expert_Systems.pdf (2016)\n[7] 0311031v1.pdf (2018)\n[8] N18-1202.pdf (2018)\n[9] 1810.04805v2.pdf (2019)\n[10] 2005.14165v4.pdf (2020)\n[11] 2201.05273v4.pdf (2022)\n[12] 2205.01068v4.pdf (2022)\n[13] 1910.10683v4.pdf (2023)\n[14] 2210.07321v4.pdf (2023)\n[15] 3641289.pdf (2024)\n[16] 1706.03762v7.pdf (2024)\n[17] 2303.18223v16.pdf (2025)\n[18] NatureDeepReview.pdf (2025)\n[19] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n[20] tanappli2016.pdf (2025)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "retrieved_chunks": [
    {
      "score": 0.5022954344749451,
      "text": ". Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.5022954344749451,
      "relevance": 3,
      "rank": 1,
      "id": "3641289.pdf::2024::85dff6bd2fb4"
    },
    {
      "score": 0.49284201860427856,
      "text": ". Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.49284201860427856,
      "relevance": 3,
      "rank": 2,
      "id": "2303.18223v16.pdf::2025::ba66543280b5"
    },
    {
      "score": 0.46609067916870117,
      "text": ". Although deep learning and simple reasoning have been used for speech and handwriting recognition for a long time, new paradigms are needed to replace rule-based manipulation of symbolic expressions by operations on large vectors101.. ■ Figure 5 | A recurrent neural network and the unfolding in time of the computation involved in its forward computation.",
      "metadata": {
        "source_file": "NatureDeepReview.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NatureDeepReview.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.46609067916870117,
      "relevance": 3,
      "rank": 3,
      "id": "NatureDeepReview.pdf::2025::507e53beaa54"
    },
    {
      "score": 0.4515981674194336,
      "text": "The rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4515981674194336,
      "relevance": 3,
      "rank": 4,
      "id": "1910.10683v4.pdf::2023::a7d0f7cc72f9"
    },
    {
      "score": 0.4493561387062073,
      "text": ". To summarize, the major contributions of this work are as follows: • The most complete survey of machine generated text detection to date, including previously omitted feature-based work and findings from recent contemporary research.. • The first detailed review of the threat models enabled by machine generated text, at a critical juncture where NLG models and tools are rapidly improving and proliferating. . • . A meaningful exploration of both topics through the lens of Trustworthy AI (TAI),",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4493561387062073,
      "relevance": 3,
      "rank": 5,
      "id": "2210.07321v4.pdf::2023::f2298e5175a1"
    },
    {
      "score": 0.4471357762813568,
      "text": ". Wang et al. proposed a two-stage planning, i.e., the first stage is to organize the story outline which illustrates the story plots and events, and the second stage is to expand the outline into a complete story.. Factuality. The input data (e.g., infobox) for text generation tasks (e.g., table-to-text generation) usually contains some factual information. . In such cases, the generated content should adhere to the original input facts. . However, lacking direct access to the input facts or ex",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.4471357762813568,
      "relevance": 3,
      "rank": 6,
      "id": "2201.05273v4.pdf::2022::853ff084cb99"
    },
    {
      "score": 0.4453848600387573,
      "text": ". Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.4453848600387573,
      "relevance": 3,
      "rank": 7,
      "id": "Expert_Systems.pdf::2016::3f868e4f3792"
    },
    {
      "score": 0.4416356682777405,
      "text": "This last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2020,
      "final_score": 0.4416356682777405,
      "relevance": 3,
      "rank": 8,
      "id": "2005.14165v4.pdf::2020::18e242ac88d3"
    },
    {
      "score": 0.4274415075778961,
      "text": ". Opened just last week, with the help of National Museums of Scotland funds and a gaggle of sponsors, the gallery at the Royal Museum offers a wealth of interactive, visually-stunning and unique displays.... The exhibition space has been divided into five main subject areas covering transport (Move It!), artificial intelligence (Robots), cloning (Me2), space travel (Blast Off!) and energy (Power Up). . Each subject area is designed around a number of significant museum objects, complemented by ",
      "metadata": {
        "source_file": "1887-Article Text-1883-1-10-20080129.pdf",
        "title": null,
        "authors": null,
        "year": "2006",
        "detected_language": null,
        "page_count": 1,
        "origin_chunk_file": "1887-Article Text-1883-1-10-20080129.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2006,
      "final_score": 0.4274415075778961,
      "relevance": 2,
      "rank": 9,
      "id": "1887-Article Text-1883-1-10-20080129.pdf::2006::fa88a06ed47a"
    },
    {
      "score": 0.4216248393058777,
      "text": ". Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.",
      "metadata": {
        "source_file": "1706.03762v7.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1706.03762v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.4216248393058777,
      "relevance": 2,
      "rank": 10,
      "id": "1706.03762v7.pdf::2024::07acaae2dd7c"
    },
    {
      "score": 0.42004626989364624,
      "text": "We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention. Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in realworld scenarios. . Finally, we identify key challenges and propose future res",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.42004626989364624,
      "relevance": 2,
      "rank": 11,
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::03120c6c5d13"
    },
    {
      "score": 0.41983187198638916,
      "text": ". Although more work is required in understanding how the model may be developed for learning, other aspects are sufficiently robust and mature for development into an industrial strength working system.. I am grateful to Thomas Connolly for constructive comments on this article. The responsibility for all errors and oversights is, of course, my own. . M. Abdelguerfiand S. Lavington, editors. . Emerging Trends in Database and Knowledge-base Machines: The Application of Parallel Architectures to ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.41983187198638916,
      "relevance": 2,
      "rank": 12,
      "id": "0311031v1.pdf::2018::62810bd2dcad"
    },
    {
      "score": 0.4177774488925934,
      "text": ". In the current paper we explore universal intelligence in much greater detail, in particular the way in which it relates to mainstream views on human intelligence and other proposed definitions of machine intelligence. Human intelligence is an enormously rich topic with a complex intellectual, social and political history. . For an overview the interested reader might want to consult \"Handbook of Intelligence\" . [Ste00] edited by R. J. Sternberg. . Our objective in this section is simply to sk",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2007,
      "final_score": 0.4177774488925934,
      "relevance": 2,
      "rank": 13,
      "id": "0712.3329v1.pdf::2007::175d12dd01ed"
    },
    {
      "score": 0.417186975479126,
      "text": ". The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition",
      "metadata": {
        "source_file": "1301.2254v1.pdf",
        "title": null,
        "authors": null,
        "year": "2001",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1301.2254v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2001,
      "final_score": 0.417186975479126,
      "relevance": 2,
      "rank": 14,
      "id": "1301.2254v1.pdf::2001::02719e1eecb2"
    },
    {
      "score": 0.39952683448791504,
      "text": "THE APPLICATION OF EXPERT SYSTEM: A REVIEW OF RESEARCH AND APPLICATIONS C. F. Tan1, L. S. Wahidin1, S. N. Khalil1, N. Tamaldin1, J. Hu2 and G.W. M. Rauterberg2 1Integrated Design Research Group, Centre for Advanced Research on Energy, Universiti Teknikal Malaysia Melaka, Durian Tunggal, Melaka, Malaysia 2Designed Intelligence Group, Department of Industrial Design, Eindhoven",
      "metadata": {
        "source_file": "tanappli2016.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 7,
        "origin_chunk_file": "tanappli2016.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.39952683448791504,
      "relevance": 2,
      "rank": 15,
      "id": "tanappli2016.pdf::2025::c8269e056e0a"
    },
    {
      "score": 0.397492915391922,
      "text": ". While this is a significant achievement, the energy cost of creating such a model is still nontrivial, and repeated efforts to replicate a model of this size will only amplify the growing compute footprint of these LLMs. We believe the entire AI community — academic researchers, civil society, policymakers, and industry — must work together to develop clear 125M 6.0e−4 0.5M 350M 3.0e−4 0.5M 1.3B . 2.0e−4 1M 2.7B 1.6e−4 1M 6.7B . 1.2e−4 2M 13B 1.0e−4 4M 30B 1.0e−4 4M 66B 0.8e−4 2M 175B 1.2e−4 2",
      "metadata": {
        "source_file": "2205.01068v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 30,
        "origin_chunk_file": "2205.01068v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.397492915391922,
      "relevance": 1,
      "rank": 16,
      "id": "2205.01068v4.pdf::2022::9943acd00d7a"
    },
    {
      "score": 0.39230969548225403,
      "text": ". To train sentence representations, prior work has used objectives to rank candidate next sentences (Jernite et al., 2017; Logeswaran and Lee, 2018), left-to-right generation of next sentence words given a representation of the previous sentence, or denoising autoencoder derived objectives. ELMo and its predecessor (Peters et al., 2017, 2018a) generalize traditional word embedding research along a different dimension. . They extract context-sensitive features from a left-to-right and a right-to",
      "metadata": {
        "source_file": "1810.04805v2.pdf",
        "title": null,
        "authors": null,
        "year": "2019",
        "detected_language": null,
        "page_count": 16,
        "origin_chunk_file": "1810.04805v2.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2019,
      "final_score": 0.39230969548225403,
      "relevance": 1,
      "rank": 17,
      "id": "1810.04805v2.pdf::2019::7f39367e0da8"
    },
    {
      "score": 0.3864052891731262,
      "text": ". Furthermore, we also use words from the future; we have obtained the best performance on the task introduced in the next section by building a log-linear classifier with four future and four history words at the input, where the training criterion is to correctly classify the current (middle) word. Training complexity is then Q = N × D + D × log2(V ). . (4) We denote this model further as CBOW, as unlike standard bag-of-words model, it uses continuous distributed representation of the context.",
      "metadata": {
        "source_file": "1301.3781v3.pdf",
        "title": null,
        "authors": null,
        "year": "2013",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "1301.3781v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2013,
      "final_score": 0.3864052891731262,
      "relevance": 1,
      "rank": 18,
      "id": "1301.3781v3.pdf::2013::315d54024385"
    },
    {
      "score": 0.38391822576522827,
      "text": ". Our baseline, the ESIM sequence model from Chen et al., uses a biLSTM to encode the premise and hypothesis, followed by a matrix attention layer, a local inference layer, another biLSTM inference composition layer, and finally a pooling operation before the output layer. Overall, adding ELMo to the ESIM model improves accuracy by an average of 0.7% across five random seeds. . A five member ensemble pushes the overall accuracy to 89.3%, exceeding the previous ensemble best of 88.9%. . Semantic ",
      "metadata": {
        "source_file": "N18-1202.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "N18-1202.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.38391822576522827,
      "relevance": 1,
      "rank": 19,
      "id": "N18-1202.pdf::2018::b65019079157"
    },
    {
      "score": 0.3820434808731079,
      "text": "In each item, the subject was asked to rate the certainty of event X happening by placing a slash on a 16 em line with certain not to happen anchoring the left end, certain to happen anchoring the right end, and uncertain labelling the midpoint Across the 12 rule items there was systematic variation in the type of connective for the antecedents (conjunctive vs. disjunctive) and the certainty and direction of the conclusion (highly vs. moderately certain to happen vs. not-happen).",
      "metadata": {
        "source_file": "1304.1083v1.pdf",
        "title": null,
        "authors": null,
        "year": "1989",
        "detected_language": null,
        "page_count": 6,
        "origin_chunk_file": "1304.1083v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of outline how ai research priorities changed between the 1980s and 2020s. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1989,
      "final_score": 0.3820434808731079,
      "relevance": 1,
      "rank": 20,
      "id": "1304.1083v1.pdf::1989::c9cff4d4d4a9"
    }
  ],
  "model_output": "The historical development and evolution of AI research priorities underwent several transformations between the 1980s and 2020s, as shown below:\n\n- In the 1980s (described in 2006 PDF [3]), artificial intelligence was presented as an interactive exhibit showcasing transport, cloning, space travel, energy, and robots. This exhibition indicates a focus on AI applications and their integration into everyday life. - During the 1980s or not stated (described in 1989 PDF [1]), researchers began using experiments to assess certainty about future events with AI systems. - In 2001 (PDF [2]), there was a shift towards developing Bayesian networks, which were used for reasoning under uncertainty and decision making. - By 2006 or not stated (PDF [3]), there were exhibits featuring AI applications in various domains such as transportation, energy, space travel, and robotics. - In 2007 (PDF [4]), the concept of transfer learning was introduced, suggesting that AI systems should be able to leverage knowledge from one domain to another. - Around 2013 (PDF [5]), there was a focus on improving natural language understanding and generation with deep learning techniques. - In 2016 (PDF [6]), expert systems remained an area of interest, demonstrating the continued relevance of rule-based AI in specific domains. - By 2018 (PDFs [7] and [8]), there was a surge in deep learning approaches for various tasks such as machine translation and text summarization. - In 2019 (PDF [9]), research focused on advancing transformers, a type of model architecture used for natural language processing tasks. - By 2020 (PDF [10]), transformer models had become dominant in the field of natural language processing, leading to significant improvements in various applications like machine translation and question answering. - In 2022 (PDFs [11] and [12]), there was a growing interest in creating large language models capable of generating coherent and contextually relevant text. - By 2023 (PDFs [13] and [14]), research expanded to include surveys on the technical evolution of large language models, as well as their potential threats, applications, and trustworthiness. - In 2024 (PDFs [15] and [16]), there was a renewed focus on the Turing Test as a benchmark for AI intelligence and the development of more advanced AI systems. - By 2025 (PDFs [17], [18], [19], and [20]), large language models were being applied to a wide range of tasks in statistics, data science, and natural language processing. There was also interest in understanding the evolution and technical development of these models. References:\n[1] 1304.1083v1.pdf (1989)\n[2] 1301.2254v1.pdf (2001)\n[3] 1887-Article Text-1883-1-10-20080129.pdf (2006)\n[4] 0712.3329v1.pdf (2007)\n[5] 1301.3781v3.pdf (2013)\n[6] Expert_Systems.pdf (2016)\n[7] 0311031v1.pdf (2018)\n[8] N18-1202.pdf (2018)\n[9] 1810.04805v2.pdf (2019)\n[10] 2005.14165v4.pdf (2020)\n[11] 2201.05273v4.pdf (2022)\n[12] 2205.01068v4.pdf (2022)\n[13] 1910.10683v4.pdf (2023)\n[14] 2210.07321v4.pdf (2023)\n[15] 3641289.pdf (2024)\n[16] 1706.03762v7.pdf (2024)\n[17] 2303.18223v16.pdf (2025)\n[18] NatureDeepReview.pdf (2025)\n[19] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n[20] tanappli2016.pdf (2025)"
}