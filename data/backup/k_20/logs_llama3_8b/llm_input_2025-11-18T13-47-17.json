{
  "timestamp": "2025-11-18T13-47-17",
  "query_refined": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "intent": "chronological",
  "prompt_final_to_llm": "You are an analytical historian of Artificial Intelligence. Describe how the concept evolved across time, highlighting paradigm shifts, milestones, and key theoretical transformations. Present findings in a coherent historical narrative ordered strictly by explicit *event years* found in the snippets. If a snippet provides no explicit event year, you MUST write '(event year not stated; described in YEAR PDF [n])'. Never guess or estimate historical periods under any circumstances. Avoid enumeration; emphasize causal relations and conceptual transitions. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles ‚Äî only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  ‚Ä¢ If an explicit event year exists in the snippet ‚Üí include it.\n  ‚Ä¢ If no explicit event year exists ‚Üí write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  ‚Ä¢ (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nTrace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.\n\nContext snippets:\n[1] 1304.1083v1.pdf (1989)\n. Although it is widely acknowledged that much of human knowledge is uncertain, it is in the field of artificial intelligence that research on the representation and management of uncertainty in rule based reasoning has been focused (Kanal & Lemmer, 1986; Hink & Woods, 1987). Most of the work on uncertainty in artificial intelligence has so far been normative, stressing issues of mathematical correctness and effectiveness. . The approach taken in this paper is not normative, but descriptive. . I\n\n[2] 1304.1082v1.pdf (1990)\n. Since our goal is to produce interpretations of probabilistic reasoning that are more compatible with human reasoning styles, we started out with an empirical study of human strategies for uncertain reasoning. This provided us with the inspiration for the design of two new and contrasting modes of explaining probabilistic reasoning, namely qualitative belief propagation and scenario-based reasoning. . It is useful to distinguish explanation as the communication of static knowledge or beliefs f\n\n[3] 1304.1106v1.pdf (1990)\n. Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime\n\n[4] 1301.2254v1.pdf (2001)\n. The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition\n\n[5] 0712.3329v1.pdf (2007)\n. A fundamental problem in artificial intelligence is that nobody really knows what intelligence is.. The problem is especially acute when we need to consider artificial systems which are significantly different to humans.\n\n[6] 1301.3781v3.pdf (2013)\n. This allows the recurrent model to form some kind of short term memory, as information from the past can be represented by the hidden layer state that gets updated based on the current input and the state of the hidden layer in the previous time step. where the word representations D have the same dimensionality as the hidden layer H. Again, the term H √ó V can be efficiently reduced to H √ó log2(V ) by using hierarchical softmax. . Most of the complexity then comes from H √ó H.\n\n[7] 1409.3215v3.pdf (2014)\n. Initially, we believed that reversing the input sentences would only lead to more confident predictions in the early parts of the target sentence and to less confident predictions in the later parts.\n\n[8] 1512.03385v1.pdf (2015)\n. On the contrary, our formulation always learns residual functions; our identity shortcuts are never closed, and all information is always passed through, with additional residual functions to be learned. In addition, highLet us consider H(x) as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.\n\n[9] Expert_Systems.pdf (2016)\nThe forward chaining approach is generally preferred in the case of a few and expensive data collection and backward chaining approach is preferred when a specific result is required with respect to large quantity of data (3). The two main tasks related to reasoning issues addressed by the inference engine are the following: 1. . After obtaining the input from the user, the inference engine decides where to start the reasoning process by going through the rules and facts that reside in the stati\n\n[10] 1409.0473v7.pdf (2016)\nAlthough most of the previous works (see, e.g., Cho et al., 2014a; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013) used to encode a variable-length input sentence into a fixed-length vector, it is not necessary, and even it may be beneficial to have a variable-length vector, as we will show later. The decoder is often trained to predict the next word yt‚Ä≤ given the context vector c and all the previously predicted words {y1, ¬∑ ¬∑ ¬∑, yt‚Ä≤‚àí1}. . In other words, the decoder defines a probabili\n\n[11] 0311031v1.pdf (2018)\n. In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: ‚Ä¢ SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not\n\n[12] 2005.14165v4.pdf (2020)\nApproach 2.1 Model and Architectures......................................... 2.2 Training Dataset.............................................. 2.3 Training Process............................................. 2.4 Evaluation................................................. Results 3.1 Language Modeling, Cloze, and Completion Tasks........................... 3.2 Closed Book Question Answering.................................... 3.3 Translation................................................ 3.4\n\n[13] 2205.01068v4.pdf (2022)\n. While this is a significant achievement, the energy cost of creating such a model is still nontrivial, and repeated efforts to replicate a model of this size will only amplify the growing compute footprint of these LLMs. We believe the entire AI community ‚Äî academic researchers, civil society, policymakers, and industry ‚Äî must work together to develop clear 125M 6.0e‚àí4 0.5M 350M 3.0e‚àí4 0.5M 1.3B . 2.0e‚àí4 1M 2.7B 1.6e‚àí4 1M 6.7B . 1.2e‚àí4 2M 13B 1.0e‚àí4 4M 30B 1.0e‚àí4 4M 66B 0.8e‚àí4 2M 175B 1.2e‚àí4 2\n\n[14] 2201.05273v4.pdf (2022)\n. Specially, DialoGPT was first trained on large-scale dialogue pairs/sessions, which could enable DialoGPT to capture the joint distribution of Pr(‚Ñéùëñùë†ùë°ùëúùëüùë¶,ùëüùëíùë†ùëùùëúùëõùë†ùëí) in conversational flow for generating relevant responses to the history utterance. Furthermore, Zeng et al. utilized the masked language modeling objective to solve generate responses based on various types of dialogue context.\n\n[15] 2210.07321v4.pdf (2023)\n3.1 Threat Modeling Fundamentals As we anticipate an audience with varying exposure to cybersecurity topics, before we present threat models related to machine generated text, it is helpful to first provide an overview of threat modeling, and characterize the approach taken in this section. A basic example of a common threat model is \"a thief who wants to steal your money\". . We can add detail to this threat model by considering more specific capabilities and objectives that such an attacker mig\n\n[16] 1910.10683v4.pdf (2023)\nThe rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.\n\n[17] 3641289.pdf (2024)\nThis statement demonstrates that supervised models significantly outperform zero-shot models in terms of performance, highlighting that an increase in parameters does not necessarily guarantee a higher level of social knowledge in this particular scenario.. 3.1.2. Reasoning. The task of reasoning poses significant challenges for an intelligent AI model. . To effectively tackle reasoning tasks, the models need to not only comprehend the provided information but also utilize reasoning and inferenc\n\n[18] 2303.18223v16.pdf (2025)\n. Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.\n\n[19] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n. Julius (Julius 2025) facilitates data science education by building a bridge that allowing professors to create interactive workflows for lessons, which can be shared with students for a seamless teaching experience through natural language interaction. In this section, we present a series of case studies conducted by a diverse range of agents, each illustrating the new data analysis paradigm facilitated through natural language interaction. . These case studies demonstrate how this approach e\n\n[20] NatureDeepReview.pdf (2025)\nIn addition to beating records in image recognition1‚Äì4 and speech recognition5‚Äì7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 1304.1083v1.pdf (1989)\n[2] 1304.1082v1.pdf (1990)\n[3] 1304.1106v1.pdf (1990)\n[4] 1301.2254v1.pdf (2001)\n[5] 0712.3329v1.pdf (2007)\n[6] 1301.3781v3.pdf (2013)\n[7] 1409.3215v3.pdf (2014)\n[8] 1512.03385v1.pdf (2015)\n[9] Expert_Systems.pdf (2016)\n[10] 1409.0473v7.pdf (2016)\n[11] 0311031v1.pdf (2018)\n[12] 2005.14165v4.pdf (2020)\n[13] 2205.01068v4.pdf (2022)\n[14] 2201.05273v4.pdf (2022)\n[15] 2210.07321v4.pdf (2023)\n[16] 1910.10683v4.pdf (2023)\n[17] 3641289.pdf (2024)\n[18] 2303.18223v16.pdf (2025)\n[19] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n[20] NatureDeepReview.pdf (2025)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "chunks_final_to_llm": [
    {
      "score": 0.5793169140815735,
      "text": ". Although it is widely acknowledged that much of human knowledge is uncertain, it is in the field of artificial intelligence that research on the representation and management of uncertainty in rule based reasoning has been focused (Kanal & Lemmer, 1986; Hink & Woods, 1987). Most of the work on uncertainty in artificial intelligence has so far been normative, stressing issues of mathematical correctness and effectiveness. . The approach taken in this paper is not normative, but descriptive. . I",
      "metadata": {
        "source_file": "1304.1083v1.pdf",
        "title": null,
        "authors": null,
        "year": "1989",
        "detected_language": null,
        "page_count": 6,
        "origin_chunk_file": "1304.1083v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1989,
      "final_score": 0.5793169140815735,
      "relevance": 3,
      "rank": 1,
      "id": "1304.1083v1.pdf::1989::e330b10ef834"
    },
    {
      "score": 0.5447474122047424,
      "text": "3.1 Threat Modeling Fundamentals As we anticipate an audience with varying exposure to cybersecurity topics, before we present threat models related to machine generated text, it is helpful to first provide an overview of threat modeling, and characterize the approach taken in this section. A basic example of a common threat model is \"a thief who wants to steal your money\". . We can add detail to this threat model by considering more specific capabilities and objectives that such an attacker mig",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.5447474122047424,
      "relevance": 3,
      "rank": 2,
      "id": "2210.07321v4.pdf::2023::9de497dca2cc"
    },
    {
      "score": 0.5283242464065552,
      "text": ". Since our goal is to produce interpretations of probabilistic reasoning that are more compatible with human reasoning styles, we started out with an empirical study of human strategies for uncertain reasoning. This provided us with the inspiration for the design of two new and contrasting modes of explaining probabilistic reasoning, namely qualitative belief propagation and scenario-based reasoning. . It is useful to distinguish explanation as the communication of static knowledge or beliefs f",
      "metadata": {
        "source_file": "1304.1082v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "1304.1082v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1990,
      "final_score": 0.5283242464065552,
      "relevance": 3,
      "rank": 3,
      "id": "1304.1082v1.pdf::1990::f5d99a04d2d3"
    },
    {
      "score": 0.5115697979927063,
      "text": ". Considering the ever-growing interest in ChatGPT and GPT models, we add a special discussion about the technical evolution of the GPT-series models, to briefly summarize the progress how they have been developed in the past years. Meanwhile, we drew a schematic diagram depicting the technological evolution of the GPT-series models in Figure 4.",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.5115697979927063,
      "relevance": 3,
      "rank": 4,
      "id": "2303.18223v16.pdf::2025::ba66543280b5"
    },
    {
      "score": 0.5012180805206299,
      "text": ". The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition",
      "metadata": {
        "source_file": "1301.2254v1.pdf",
        "title": null,
        "authors": null,
        "year": "2001",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1301.2254v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2001,
      "final_score": 0.5012180805206299,
      "relevance": 3,
      "rank": 5,
      "id": "1301.2254v1.pdf::2001::02719e1eecb2"
    },
    {
      "score": 0.4982433319091797,
      "text": "The rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4982433319091797,
      "relevance": 3,
      "rank": 6,
      "id": "1910.10683v4.pdf::2023::a7d0f7cc72f9"
    },
    {
      "score": 0.4951702356338501,
      "text": ". In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: ‚Ä¢ SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.4951702356338501,
      "relevance": 3,
      "rank": 7,
      "id": "0311031v1.pdf::2018::17b63504fb56"
    },
    {
      "score": 0.49371713399887085,
      "text": "This statement demonstrates that supervised models significantly outperform zero-shot models in terms of performance, highlighting that an increase in parameters does not necessarily guarantee a higher level of social knowledge in this particular scenario.. 3.1.2. Reasoning. The task of reasoning poses significant challenges for an intelligent AI model. . To effectively tackle reasoning tasks, the models need to not only comprehend the provided information but also utilize reasoning and inferenc",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.49371713399887085,
      "relevance": 3,
      "rank": 8,
      "id": "3641289.pdf::2024::ecc662314003"
    },
    {
      "score": 0.4922081530094147,
      "text": ". Julius (Julius 2025) facilitates data science education by building a bridge that allowing professors to create interactive workflows for lessons, which can be shared with students for a seamless teaching experience through natural language interaction. In this section, we present a series of case studies conducted by a diverse range of agents, each illustrating the new data analysis paradigm facilitated through natural language interaction. . These case studies demonstrate how this approach e",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.4922081530094147,
      "relevance": 2,
      "rank": 9,
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::d66fb2582f37"
    },
    {
      "score": 0.4880554676055908,
      "text": ". Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime",
      "metadata": {
        "source_file": "1304.1106v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1304.1106v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1990,
      "final_score": 0.4880554676055908,
      "relevance": 2,
      "rank": 10,
      "id": "1304.1106v1.pdf::1990::6ce03695c520"
    },
    {
      "score": 0.4851933717727661,
      "text": "In addition to beating records in image recognition1‚Äì4 and speech recognition5‚Äì7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.",
      "metadata": {
        "source_file": "NatureDeepReview.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NatureDeepReview.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.4851933717727661,
      "relevance": 2,
      "rank": 11,
      "id": "NatureDeepReview.pdf::2025::b3d9208bbfb5"
    },
    {
      "score": 0.48371949791908264,
      "text": "The forward chaining approach is generally preferred in the case of a few and expensive data collection and backward chaining approach is preferred when a specific result is required with respect to large quantity of data (3). The two main tasks related to reasoning issues addressed by the inference engine are the following: 1. . After obtaining the input from the user, the inference engine decides where to start the reasoning process by going through the rules and facts that reside in the stati",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.48371949791908264,
      "relevance": 2,
      "rank": 12,
      "id": "Expert_Systems.pdf::2016::94c1f0d33748"
    },
    {
      "score": 0.48130881786346436,
      "text": "Approach 2.1 Model and Architectures......................................... 2.2 Training Dataset.............................................. 2.3 Training Process............................................. 2.4 Evaluation................................................. Results 3.1 Language Modeling, Cloze, and Completion Tasks........................... 3.2 Closed Book Question Answering.................................... 3.3 Translation................................................ 3.4 ",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2020,
      "final_score": 0.48130881786346436,
      "relevance": 2,
      "rank": 13,
      "id": "2005.14165v4.pdf::2020::b18961a6fe8c"
    },
    {
      "score": 0.4588938355445862,
      "text": ". While this is a significant achievement, the energy cost of creating such a model is still nontrivial, and repeated efforts to replicate a model of this size will only amplify the growing compute footprint of these LLMs. We believe the entire AI community ‚Äî academic researchers, civil society, policymakers, and industry ‚Äî must work together to develop clear 125M 6.0e‚àí4 0.5M 350M 3.0e‚àí4 0.5M 1.3B . 2.0e‚àí4 1M 2.7B 1.6e‚àí4 1M 6.7B . 1.2e‚àí4 2M 13B 1.0e‚àí4 4M 30B 1.0e‚àí4 4M 66B 0.8e‚àí4 2M 175B 1.2e‚àí4 2",
      "metadata": {
        "source_file": "2205.01068v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 30,
        "origin_chunk_file": "2205.01068v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.4588938355445862,
      "relevance": 2,
      "rank": 14,
      "id": "2205.01068v4.pdf::2022::9943acd00d7a"
    },
    {
      "score": 0.45680785179138184,
      "text": ". Specially, DialoGPT was first trained on large-scale dialogue pairs/sessions, which could enable DialoGPT to capture the joint distribution of Pr(‚Ñéùëñùë†ùë°ùëúùëüùë¶,ùëüùëíùë†ùëùùëúùëõùë†ùëí) in conversational flow for generating relevant responses to the history utterance. Furthermore, Zeng et al. utilized the masked language modeling objective to solve generate responses based on various types of dialogue context.",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.45680785179138184,
      "relevance": 2,
      "rank": 15,
      "id": "2201.05273v4.pdf::2022::8be812cb551c"
    },
    {
      "score": 0.45515990257263184,
      "text": ". Initially, we believed that reversing the input sentences would only lead to more confident predictions in the early parts of the target sentence and to less confident predictions in the later parts.",
      "metadata": {
        "source_file": "1409.3215v3.pdf",
        "title": null,
        "authors": null,
        "year": "2014",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "1409.3215v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2014,
      "final_score": 0.45515990257263184,
      "relevance": 1,
      "rank": 16,
      "id": "1409.3215v3.pdf::2014::870c12fdf8f1"
    },
    {
      "score": 0.4483989179134369,
      "text": ". A fundamental problem in artificial intelligence is that nobody really knows what intelligence is.. The problem is especially acute when we need to consider artificial systems which are significantly different to humans.",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2007,
      "final_score": 0.4483989179134369,
      "relevance": 1,
      "rank": 17,
      "id": "0712.3329v1.pdf::2007::763164362c30"
    },
    {
      "score": 0.43683555722236633,
      "text": ". This allows the recurrent model to form some kind of short term memory, as information from the past can be represented by the hidden layer state that gets updated based on the current input and the state of the hidden layer in the previous time step. where the word representations D have the same dimensionality as the hidden layer H. Again, the term H √ó V can be efficiently reduced to H √ó log2(V ) by using hierarchical softmax. . Most of the complexity then comes from H √ó H.",
      "metadata": {
        "source_file": "1301.3781v3.pdf",
        "title": null,
        "authors": null,
        "year": "2013",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "1301.3781v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2013,
      "final_score": 0.43683555722236633,
      "relevance": 1,
      "rank": 18,
      "id": "1301.3781v3.pdf::2013::df63c1f5622b"
    },
    {
      "score": 0.42666566371917725,
      "text": ". On the contrary, our formulation always learns residual functions; our identity shortcuts are never closed, and all information is always passed through, with additional residual functions to be learned. In addition, highLet us consider H(x) as an underlying mapping to be fit by a few stacked layers (not necessarily the entire net), with x denoting the inputs to the first of these layers.",
      "metadata": {
        "source_file": "1512.03385v1.pdf",
        "title": null,
        "authors": null,
        "year": "2015",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "1512.03385v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2015,
      "final_score": 0.42666566371917725,
      "relevance": 1,
      "rank": 19,
      "id": "1512.03385v1.pdf::2015::6c9823640400"
    },
    {
      "score": 0.4226810932159424,
      "text": "Although most of the previous works (see, e.g., Cho et al., 2014a; Sutskever et al., 2014; Kalchbrenner and Blunsom, 2013) used to encode a variable-length input sentence into a fixed-length vector, it is not necessary, and even it may be beneficial to have a variable-length vector, as we will show later. The decoder is often trained to predict the next word yt‚Ä≤ given the context vector c and all the previously predicted words {y1, ¬∑ ¬∑ ¬∑, yt‚Ä≤‚àí1}. . In other words, the decoder defines a probabili",
      "metadata": {
        "source_file": "1409.0473v7.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1409.0473v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of explain how uncertainty is modeled in ai systems across decades. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.4226810932159424,
      "relevance": 1,
      "rank": 20,
      "id": "1409.0473v7.pdf::2016::cd32a9680349"
    }
  ]
}