{
  "timestamp": "2025-11-18T11-12-52",
  "query_refined": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
  "intent": "chronological",
  "prompt_final_to_llm": "You are an analytical historian of Artificial Intelligence. Describe how the concept evolved across time, highlighting paradigm shifts, milestones, and key theoretical transformations. Present findings in a coherent historical narrative ordered strictly by explicit *event years* found in the snippets. If a snippet provides no explicit event year, you MUST write '(event year not stated; described in YEAR PDF [n])'. Never guess or estimate historical periods under any circumstances. Avoid enumeration; emphasize causal relations and conceptual transitions. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles — only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  • If an explicit event year exists in the snippet → include it.\n  • If no explicit event year exists → write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  • (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nTrace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.\n\nContext snippets:\n[1] 1304.1106v1.pdf (1990)\n. Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime\n\n[2] 1301.2254v1.pdf (2001)\n. The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition\n\n[3] 0712.3329v1.pdf (2007)\n. We then examine some of the properties of universal intelligence, such as its ability to sensibly order simple learning algorithms and connections to the theory of universal optimal learning agents.. Section 4 overviews other definitions and tests of machine intelligence that have been proposed. Although surveys of the Turing test and its many variants exist, for example [SCA00], as far as we know this section is the first general survey of definitions and tests of machine intelligence. . Give\n\n[4] 1301.3781v3.pdf (2013)\n. The main goal of this paper is to introduce techniques that can be used for learning high-quality word vectors from huge data sets with billions of words, and with millions of words in the vocabulary.\n\n[5] D14-1162.pdf (2014)\nThe result, GloVe, is a new global log-bilinear regression model for the unsupervised learning of word representations that outperforms other models on word analogy, word similarity, and named entity recognition tasks.. Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski.. 2014. Don't count, predict! . A\nsystematic comparison of context-counting vs. context-predicting semantic vectors. . In. . Extracting semantic representations from word cooccurrence statistics: A computational study. . Behavi\n\n[6] NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf (2014)\nThe specific contributions of this paper are as follows: we trained one of the largest convolutional neural networks to date on the subsets of ImageNet used in the ILSVRC-2010 and ILSVRC-2012 competitions and achieved by far the best results ever reported on these datasets. We wrote a highly-optimized GPU implementation of 2D convolution and all the other operations inherent in training convolutional neural networks, which we make available publicly1. . Our network contains a number of new and u\n\n[7] 1409.3215v3.pdf (2014)\n. Initially, we believed that reversing the input sentences would only lead to more confident predictions in the early parts of the target sentence and to less confident predictions in the later parts.\n\n[8] Expert_Systems.pdf (2016)\n. Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre\n\n[9] 1409.0473v7.pdf (2016)\nAdding neural components to existing translation systems, for instance, to score the phrase pairs in the phrase table or to re-rank candidate translations, has allowed to surpass the previous state-of-the-art performance level.\n\n[10] 0311031v1.pdf (2018)\n. Although more work is required in understanding how the model may be developed for learning, other aspects are sufficiently robust and mature for development into an industrial strength working system.. I am grateful to Thomas Connolly for constructive comments on this article. The responsibility for all errors and oversights is, of course, my own. . M. Abdelguerfiand S. Lavington, editors. . Emerging Trends in Database and Knowledge-base Machines: The Application of Parallel Architectures to\n\n[11] N18-1202.pdf (2018)\n. Through ablations and other controlled experiments, we have also confirmed that the biLM layers efficiently encode different types of syntactic and semantic information about wordsin-context, and that using all layers improves overall task performance.. san Sajjad, and James R. Glass. 2017. What do neural machine translation models learn about morphology? . In. . A large annotated corpus for learning natural language inference. . In. . One billion word benchmark for measuring progress in stati\n\n[12] 2005.14165v4.pdf (2020)\nThis last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].\n\n[13] 2201.05273v4.pdf (2022)\n. For the query-focused summarization task, Pasunuru et al. used a search engine, i.e., Bing, to retrieve the answer paragraph as the synthetic summary and used the top ranked documents as input text.. Another line of work is to use perturbation-based methods by corrupting the original text. For example, Chen et al. presented a set of data augmentation methods for conversation summarization, such as random swapping/deletion to randomly swap or delete utterances in conversations. . Multi-Task Lea\n\n[14] 2210.07321v4.pdf (2023)\n. To summarize, the major contributions of this work are as follows: • The most complete survey of machine generated text detection to date, including previously omitted feature-based work and findings from recent contemporary research.. • The first detailed review of the threat models enabled by machine generated text, at a critical juncture where NLG models and tools are rapidly improving and proliferating. . • . A meaningful exploration of both topics through the lens of Trustworthy AI (TAI),\n\n[15] 1910.10683v4.pdf (2023)\n. By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.\n\n[16] 3641289.pdf (2024)\n. Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and\n\n[17] 1706.03762v7.pdf (2024)\n. Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.\n\n[18] 2303.18223v16.pdf (2025)\nRecently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. . Considering this rapid technical progress, in this survey, we review the recent advance\n\n[19] NatureDeepReview.pdf (2025)\nIn addition to beating records in image recognition1–4 and speech recognition5–7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.\n\n[20] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n. LAMBDA facilitates an interactive analysis process, enabling us to perform tasks such as data processing, feature engineering, model training, parameter tuning, and evaluation through a series of guided conversations. Finally, we used LAMBDA's built-in report generation feature to compile a analysis report, which includes details of the tasks completed in the conversation history. . The analysis process, including the conversation and the generated report, is presented in Figure 6. . As beginn\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 1304.1106v1.pdf (1990)\n[2] 1301.2254v1.pdf (2001)\n[3] 0712.3329v1.pdf (2007)\n[4] 1301.3781v3.pdf (2013)\n[5] D14-1162.pdf (2014)\n[6] NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf (2014)\n[7] 1409.3215v3.pdf (2014)\n[8] Expert_Systems.pdf (2016)\n[9] 1409.0473v7.pdf (2016)\n[10] 0311031v1.pdf (2018)\n[11] N18-1202.pdf (2018)\n[12] 2005.14165v4.pdf (2020)\n[13] 2201.05273v4.pdf (2022)\n[14] 2210.07321v4.pdf (2023)\n[15] 1910.10683v4.pdf (2023)\n[16] 3641289.pdf (2024)\n[17] 1706.03762v7.pdf (2024)\n[18] 2303.18223v16.pdf (2025)\n[19] NatureDeepReview.pdf (2025)\n[20] A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf (2025)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "chunks_final_to_llm": [
    {
      "score": 0.5169284343719482,
      "text": "Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. . Considering this rapid technical progress, in this survey, we review the recent advance",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.5169284343719482,
      "relevance": 3,
      "rank": 1,
      "id": "2303.18223v16.pdf::2025::ea3b381a808a"
    },
    {
      "score": 0.5047246217727661,
      "text": ". Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.5047246217727661,
      "relevance": 3,
      "rank": 2,
      "id": "3641289.pdf::2024::85dff6bd2fb4"
    },
    {
      "score": 0.49848613142967224,
      "text": ". To summarize, the major contributions of this work are as follows: • The most complete survey of machine generated text detection to date, including previously omitted feature-based work and findings from recent contemporary research.. • The first detailed review of the threat models enabled by machine generated text, at a critical juncture where NLG models and tools are rapidly improving and proliferating. . • . A meaningful exploration of both topics through the lens of Trustworthy AI (TAI),",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.49848613142967224,
      "relevance": 3,
      "rank": 3,
      "id": "2210.07321v4.pdf::2023::f2298e5175a1"
    },
    {
      "score": 0.49770843982696533,
      "text": "In addition to beating records in image recognition1–4 and speech recognition5–7, it has beaten other machine-learning techniques at predicting the activ ity of potential drug molecules8, analysing particle accelerator data9,10, reconstructing brain circuits11, and predicting the effects of mutations in non-coding DNA on gene expression and disease12,13.",
      "metadata": {
        "source_file": "NatureDeepReview.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NatureDeepReview.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.49770843982696533,
      "relevance": 3,
      "rank": 4,
      "id": "NatureDeepReview.pdf::2025::b3d9208bbfb5"
    },
    {
      "score": 0.49193525314331055,
      "text": ". For the query-focused summarization task, Pasunuru et al. used a search engine, i.e., Bing, to retrieve the answer paragraph as the synthetic summary and used the top ranked documents as input text.. Another line of work is to use perturbation-based methods by corrupting the original text. For example, Chen et al. presented a set of data augmentation methods for conversation summarization, such as random swapping/deletion to randomly swap or delete utterances in conversations. . Multi-Task Lea",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2022,
      "final_score": 0.49193525314331055,
      "relevance": 3,
      "rank": 5,
      "id": "2201.05273v4.pdf::2022::7e185834e6cc"
    },
    {
      "score": 0.48595482110977173,
      "text": ". LAMBDA facilitates an interactive analysis process, enabling us to perform tasks such as data processing, feature engineering, model training, parameter tuning, and evaluation through a series of guided conversations. Finally, we used LAMBDA's built-in report generation feature to compile a analysis report, which includes details of the tasks completed in the conversation history. . The analysis process, including the conversation and the generated report, is presented in Figure 6. . As beginn",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2025,
      "final_score": 0.48595482110977173,
      "relevance": 3,
      "rank": 6,
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::f38b966bb5f1"
    },
    {
      "score": 0.4848301112651825,
      "text": ". By combining the insights from our exploration with scale and our new \"Colossal Clean Crawled Corpus\", we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2023,
      "final_score": 0.4848301112651825,
      "relevance": 3,
      "rank": 7,
      "id": "1910.10683v4.pdf::2023::c685c979c854"
    },
    {
      "score": 0.4725559651851654,
      "text": ". Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.4725559651851654,
      "relevance": 2,
      "rank": 8,
      "id": "Expert_Systems.pdf::2016::3f868e4f3792"
    },
    {
      "score": 0.45822176337242126,
      "text": ". Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.",
      "metadata": {
        "source_file": "1706.03762v7.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1706.03762v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2024,
      "final_score": 0.45822176337242126,
      "relevance": 2,
      "rank": 9,
      "id": "1706.03762v7.pdf::2024::07acaae2dd7c"
    },
    {
      "score": 0.45536667108535767,
      "text": "This last paradigm has led to substantial progress on many challenging NLP tasks such as reading comprehension, question answering, textual entailment, and many others, and has continued to advance based on new architectures and algorithms [RSR+19, LOG+19, YDY+19, LCG+19].",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2020,
      "final_score": 0.45536667108535767,
      "relevance": 2,
      "rank": 10,
      "id": "2005.14165v4.pdf::2020::18e242ac88d3"
    },
    {
      "score": 0.44970715045928955,
      "text": "The result, GloVe, is a new global log-bilinear regression model for the unsupervised learning of word representations that outperforms other models on word analogy, word similarity, and named entity recognition tasks.. Marco Baroni, Georgiana Dinu, and Germ´an Kruszewski.. 2014. Don't count, predict! . A\nsystematic comparison of context-counting vs. context-predicting semantic vectors. . In. . Extracting semantic representations from word cooccurrence statistics: A computational study. . Behavi",
      "metadata": {
        "source_file": "D14-1162.pdf",
        "title": null,
        "authors": null,
        "year": "2014",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "D14-1162.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2014,
      "final_score": 0.44970715045928955,
      "relevance": 2,
      "rank": 11,
      "id": "D14-1162.pdf::2014::a47cb0a05267"
    },
    {
      "score": 0.43432584404945374,
      "text": ". The ancestor sets A logic program P together with a goal G, defines an SLD tree each branch of which is a refutation of G using P. no ENs with s, l and b as nodes\") we (essentially) get BNT REE as an SLD-tree.. Each successful branch re (logs of) the probabilities added be>.. = (>.1, >.2,..., An). For any goal G, S has an associated SLD-tree: the one for of the well-known 'Asia' network given in Fig 3. . This is BN19 in Fig 5. . We then used a uniform prior over the set ing a cyclic transition",
      "metadata": {
        "source_file": "1301.2254v1.pdf",
        "title": null,
        "authors": null,
        "year": "2001",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1301.2254v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2001,
      "final_score": 0.43432584404945374,
      "relevance": 2,
      "rank": 12,
      "id": "1301.2254v1.pdf::2001::02719e1eecb2"
    },
    {
      "score": 0.4304146468639374,
      "text": "Adding neural components to existing translation systems, for instance, to score the phrase pairs in the phrase table or to re-rank candidate translations, has allowed to surpass the previous state-of-the-art performance level.",
      "metadata": {
        "source_file": "1409.0473v7.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1409.0473v7.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2016,
      "final_score": 0.4304146468639374,
      "relevance": 2,
      "rank": 13,
      "id": "1409.0473v7.pdf::2016::3b42055a39aa"
    },
    {
      "score": 0.4290715456008911,
      "text": ". We then examine some of the properties of universal intelligence, such as its ability to sensibly order simple learning algorithms and connections to the theory of universal optimal learning agents.. Section 4 overviews other definitions and tests of machine intelligence that have been proposed. Although surveys of the Turing test and its many variants exist, for example [SCA00], as far as we know this section is the first general survey of definitions and tests of machine intelligence. . Give",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2007,
      "final_score": 0.4290715456008911,
      "relevance": 2,
      "rank": 14,
      "id": "0712.3329v1.pdf::2007::d93703f6d548"
    },
    {
      "score": 0.42604315280914307,
      "text": "The specific contributions of this paper are as follows: we trained one of the largest convolutional neural networks to date on the subsets of ImageNet used in the ILSVRC-2010 and ILSVRC-2012 competitions and achieved by far the best results ever reported on these datasets. We wrote a highly-optimized GPU implementation of 2D convolution and all the other operations inherent in training convolutional neural networks, which we make available publicly1. . Our network contains a number of new and u",
      "metadata": {
        "source_file": "NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf",
        "title": null,
        "authors": null,
        "year": "2014",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2014,
      "final_score": 0.42604315280914307,
      "relevance": 1,
      "rank": 15,
      "id": "NIPS-2012-imagenet-classification-with-deep-convolutional-neural-networks-Paper.pdf::2014::6df2ecb9ead0"
    },
    {
      "score": 0.4219875931739807,
      "text": ". Although more work is required in understanding how the model may be developed for learning, other aspects are sufficiently robust and mature for development into an industrial strength working system.. I am grateful to Thomas Connolly for constructive comments on this article. The responsibility for all errors and oversights is, of course, my own. . M. Abdelguerfiand S. Lavington, editors. . Emerging Trends in Database and Knowledge-base Machines: The Application of Parallel Architectures to ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.4219875931739807,
      "relevance": 1,
      "rank": 16,
      "id": "0311031v1.pdf::2018::62810bd2dcad"
    },
    {
      "score": 0.42164862155914307,
      "text": ". Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime",
      "metadata": {
        "source_file": "1304.1106v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1304.1106v1.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 1990,
      "final_score": 0.42164862155914307,
      "relevance": 1,
      "rank": 17,
      "id": "1304.1106v1.pdf::1990::6ce03695c520"
    },
    {
      "score": 0.413790225982666,
      "text": ". The main goal of this paper is to introduce techniques that can be used for learning high-quality word vectors from huge data sets with billions of words, and with millions of words in the vocabulary.",
      "metadata": {
        "source_file": "1301.3781v3.pdf",
        "title": null,
        "authors": null,
        "year": "2013",
        "detected_language": null,
        "page_count": 12,
        "origin_chunk_file": "1301.3781v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2013,
      "final_score": 0.413790225982666,
      "relevance": 1,
      "rank": 18,
      "id": "1301.3781v3.pdf::2013::fc3c1b1f83df"
    },
    {
      "score": 0.4127931594848633,
      "text": ". Through ablations and other controlled experiments, we have also confirmed that the biLM layers efficiently encode different types of syntactic and semantic information about wordsin-context, and that using all layers improves overall task performance.. san Sajjad, and James R. Glass. 2017. What do neural machine translation models learn about morphology? . In. . A large annotated corpus for learning natural language inference. . In. . One billion word benchmark for measuring progress in stati",
      "metadata": {
        "source_file": "N18-1202.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "N18-1202.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2018,
      "final_score": 0.4127931594848633,
      "relevance": 1,
      "rank": 19,
      "id": "N18-1202.pdf::2018::0b802400e582"
    },
    {
      "score": 0.4104801416397095,
      "text": ". Initially, we believed that reversing the input sentences would only lead to more confident predictions in the early parts of the target sentence and to less confident predictions in the later parts.",
      "metadata": {
        "source_file": "1409.3215v3.pdf",
        "title": null,
        "authors": null,
        "year": "2014",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "1409.3215v3.chunks.json"
      },
      "query": "Trace the historical development and evolution of summarize how search algorithms contributed to early ai progress. strictly through the explicit event years present in the snippets. If no explicit event year is present for a point, note that the event year is not stated.",
      "year": 2014,
      "final_score": 0.4104801416397095,
      "relevance": 1,
      "rank": 20,
      "id": "1409.3215v3.pdf::2014::870c12fdf8f1"
    }
  ]
}