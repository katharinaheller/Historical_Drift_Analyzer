{
  "timestamp": "2025-11-16T20-07-34",
  "query_refined": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
  "intent": "conceptual",
  "prompt_final_to_llm": "You are a domain expert in Artificial Intelligence. Provide a precise definition, clarify theoretical foundations, and explain how interpretations evolved across time and publications. Use event years ONLY if explicitly stated in the snippets. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles — only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  • If an explicit event year exists in the snippet → include it.\n  • If no explicit event year exists → write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  • (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nDefine summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.\n\nContext snippets:\n[1] 3641289.pdf (2024)\nIn addition, LLMs like GPT-3 were found to have moral biases in terms of the Moral Foundation theory; The study conducted by reveals that existing LMs have potential in ethical judgment, but still need improvement. proposes a Chinese conversational bias evaluation dataset CHBias, discovers bias risks in pre-trained models, and explores debiasing methods. Moreover, in the assessment of GPT-4 alignment, discovered a systematic bias. . ChatGPT is also observed to exhibit somewhat bias on cultural v\n\n[2] 2201.05273v4.pdf (2022)\n. It has been shown that the generated texts from PLMs are likely to be biased towards some attributes, i.e., favoring a particular race, gender or aged people, which is not desired for the text generation tasks. These undesirable biases are unexpectedly hidden in model components such as word embeddings and attention heads. . A simple approach to mitigating the gender bias in word embeddings is to \"swap\" gendered terms in training data when generating word embeddings. . Furthermore, simply mask\n\n[2] 2201.05273v4.pdf (2022)\n. Furthermore, to make summarization models produce more factual summaries, some studies proposed evaluation metrics or correction methods to measure and revise the generated text for preserving factuality.. Controllability. In text generation, many applications need a good control over the output text. . For example, to generate reading materials for kids, we would like to guide the output stories to be safe, educational and easily understandable by children.\n\n[1] 3641289.pdf (2024)\n. As for new adversarial datasets, Wang et al. introduced AdvGLUE++ benchmark data for assessing adversarial robustness and implemented a new evaluation protocol to scrutinize machine ethics via jailbreaking system prompts.. 3.2.2 Ethics and Bias.\n\n[1] 3641289.pdf (2024)\nAt the same time, attention should be paid to the impartiality and neutrality of the language in order to mitigate any potential biases, including English bias or other biases, that could impact multilingual applications.. 3.1.5 Factuality. Factuality in the context of LLMs refers to the extent to which the information or answers provided by the model align with real-world truths and verifiable facts.\n\n[3] 0311031v1.pdf (2018)\n. In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: • SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not\n\n[4] reluICML.pdf (2010)\nThen we repeatedly update each weight, wij, using the difference between two measured, pairwise correlations where ǫ is a learning rate, data is the frequency with which visible unit i and hidden unit j are on together when the feature detectors are being driven by images from the training set and recon is the corresponding frequency when the hidden units are being driven by reconstructed images. A similar learning rule can be used for the biases. . where bj is the bias of j and vi is the binary\n\n[2] 2201.05273v4.pdf (2022)\n. In recent literature, data augmentation has emerged as a critical method for increasing the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. One line of research is to use retrieval models to obtain real data from external corpora as the augmented data.\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 3641289.pdf (2024)\n[2] 2201.05273v4.pdf (2022)\n[3] 0311031v1.pdf (2018)\n[4] reluICML.pdf (2010)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "chunks_final_to_llm": [
    {
      "score": 0.38528144359588623,
      "text": "In addition, LLMs like GPT-3 were found to have moral biases in terms of the Moral Foundation theory; The study conducted by reveals that existing LMs have potential in ethical judgment, but still need improvement. proposes a Chinese conversational bias evaluation dataset CHBias, discovers bias risks in pre-trained models, and explores debiasing methods. Moreover, in the assessment of GPT-4 alignment, discovered a systematic bias. . ChatGPT is also observed to exhibit somewhat bias on cultural v",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -2.8634699285030365,
      "relevance": 3,
      "rank": 1,
      "id": "3641289.pdf::2024::afc702007d9c"
    },
    {
      "score": 0.42848291993141174,
      "text": ". It has been shown that the generated texts from PLMs are likely to be biased towards some attributes, i.e., favoring a particular race, gender or aged people, which is not desired for the text generation tasks. These undesirable biases are unexpectedly hidden in model components such as word embeddings and attention heads. . A simple approach to mitigating the gender bias in word embeddings is to \"swap\" gendered terms in training data when generating word embeddings. . Furthermore, simply mask",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -3.5523865446448326,
      "relevance": 3,
      "rank": 2,
      "id": "2201.05273v4.pdf::2022::006bd10b6475"
    },
    {
      "score": 0.4370036721229553,
      "text": ". Furthermore, to make summarization models produce more factual summaries, some studies proposed evaluation metrics or correction methods to measure and revise the generated text for preserving factuality.. Controllability. In text generation, many applications need a good control over the output text. . For example, to generate reading materials for kids, we would like to guide the output stories to be safe, educational and easily understandable by children.",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -4.042414531111717,
      "relevance": 3,
      "rank": 3,
      "id": "2201.05273v4.pdf::2022::bcb2357ff742"
    },
    {
      "score": 0.3833816349506378,
      "text": ". As for new adversarial datasets, Wang et al. introduced AdvGLUE++ benchmark data for assessing adversarial robustness and implemented a new evaluation protocol to scrutinize machine ethics via jailbreaking system prompts.. 3.2.2 Ethics and Bias.",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -4.049427799880505,
      "relevance": 3,
      "rank": 4,
      "id": "3641289.pdf::2024::42b119384bd6"
    },
    {
      "score": 0.4801763594150543,
      "text": "At the same time, attention should be paid to the impartiality and neutrality of the language in order to mitigate any potential biases, including English bias or other biases, that could impact multilingual applications.. 3.1.5 Factuality. Factuality in the context of LLMs refers to the extent to which the information or answers provided by the model align with real-world truths and verifiable facts.",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -4.258099220693111,
      "relevance": 3,
      "rank": 5,
      "id": "3641289.pdf::2024::db8f6d33a287"
    },
    {
      "score": 0.39138704538345337,
      "text": ". In the development of the SP theory, computer models have been created as a way of reducing vagueness and inconsistencies in the theory, as a way of verifying that the system really does work according to expectations, and as a means of demonstrating what the system can do. Two main models have been developed to date: • SP61 which is a partial model of the system that builds multiple alignments from New and Old patterns (Wolff, 2000). . This model does not attempt any learning and it does not ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -5.052318200469017,
      "relevance": 3,
      "rank": 6,
      "id": "0311031v1.pdf::2018::17b63504fb56"
    },
    {
      "score": 0.36865025758743286,
      "text": "Then we repeatedly update each weight, wij, using the difference between two measured, pairwise correlations where ǫ is a learning rate, data is the frequency with which visible unit i and hidden unit j are on together when the feature detectors are being driven by images from the training set and recon is the corresponding frequency when the hidden units are being driven by reconstructed images. A similar learning rule can be used for the biases. . where bj is the bias of j and vi is the binary",
      "metadata": {
        "source_file": "reluICML.pdf",
        "title": null,
        "authors": null,
        "year": "2010",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "reluICML.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -5.09977225959301,
      "relevance": 3,
      "rank": 7,
      "id": "reluICML.pdf::2010::0c566d44b02d"
    },
    {
      "score": 0.38621628284454346,
      "text": ". In recent literature, data augmentation has emerged as a critical method for increasing the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. One line of research is to use retrieval models to obtain real data from external corpora as the augmented data.",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Define summarize how bias is introduced through data or model assumptions., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "final_score": -5.112024039030075,
      "relevance": 3,
      "rank": 8,
      "id": "2201.05273v4.pdf::2022::1292775a2900"
    }
  ]
}