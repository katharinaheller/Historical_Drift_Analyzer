{
  "timestamp": "2025-11-19T00-38-44",
  "query_id": "Define_provide_a_rigorous_definition_of_ai_using_only_the_provided_context___des",
  "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
  "query_refined": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
  "intent": "conceptual",
  "prompt_final_to_llm": "You are a domain expert in Artificial Intelligence. Provide a precise definition, clarify theoretical foundations, and explain how interpretations evolved across time and publications. Use event years ONLY if explicitly stated in the snippets. Use numeric IEEE-style citations [1], [2], etc., for statements supported by the provided snippets. Each number corresponds to one unique PDF listed below. Multiple snippets originating from the same PDF share the same number. Never assign multiple citation numbers to the same source.\n\n**Your final answer MUST end with a separate section titled 'References'.**\nThis section MUST list all unique PDFs exactly once, in the following strict format:\n[n] FILENAME.pdf (YEAR)\n\nDo not fabricate author names, journals, or article titles — only use the given filename and metadata year.\n\nTemporal Attribution Rules:\n1. You may ONLY use event years that appear explicitly in the snippet text.\n2. If the snippet text explicitly contains a year (e.g., 'In the 1950s', 'In 1976'), treat that as the factual historical reference.\n3. If a snippet DOES NOT contain an explicit event year, you MUST NOT guess, infer, approximate, or estimate any year.\n   Instead, write exactly: '(event year not stated; described in YEAR PDF [n])'.\n4. The metadata publication year indicates only when the PDF was published, not when the events occurred.\n5. Never replace or override an explicit event year with a metadata year.\n6. Never deduce approximate historical periods from textual content (e.g., never infer '1990s' unless explicitly stated).\n\nOutput Structuring Guidelines:\n- For every key historical or conceptual point:\n  • If an explicit event year exists in the snippet → include it.\n  • If no explicit event year exists → write '(event year not stated; described in YEAR PDF [n])'.\n- Recommended dual-year structure:\n  • (1950s; described in 2025 PDF [7]) The Turing Test was proposed as a benchmark.\nThis dual timestamping ensures full temporal grounding without hallucination.\n\nIMPORTANT:\n**Your output MUST end with a final section titled 'References'.**\nThis section must list all unique PDFs exactly once in IEEE numeric format.\n\nRefined query:\nDefine provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.\n\nContext snippets:\n[1] 3641289.pdf (2024)\n. Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and\n\n[1] 3641289.pdf (2024)\n. We consistently maintain the related open-source materials at: INTRODUCTION Understanding the essence of intelligence and establishing whether a machine embodies it poses a compelling question for scientists. It is generally agreed upon that authentic intelligence equips us with reasoning capabilities, enables us to test hypotheses, and prepares for future eventualities. . In particular, Artificial Intelligence (AI) researchers focus on the development of machine-based intelligence, as opposed\n\n[1] 3641289.pdf (2024)\n. A significant takeaway from previous attempts is the paramount importance of AI evaluation, which serves as a critical tool to identify current system limitations and inform the design of more powerful models. Recently, large language models (LLMs) have incited substantial interest across both academic and industrial domains. . As demonstrated by existing work, the great performance of LLMs has raised promise that they could be AGI in this era. . LLMs possess the capabilities to solve diverse\n\n[2] 2303.18223v16.pdf (2025)\n. Abstract—Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine.. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language.\n\n[3] 0712.3329v1.pdf (2007)\n. In this paper we approach the problem of defining machine intelligence as follows: Section 2 overviews well known theories, definitions and tests of intelligence that have been developed by psychologists. Our objective in this section is to gain an understanding of the essence of intelligence in the broadest possible terms. . In particular we are interested in commonly expressed ideas that could be applied to arbitrary systems and contexts, not just humans. . Section 3 takes these key ideas an\n\nAnswer the refined query using only the context above. Use numeric citations. If a claim lacks evidence write 'insufficient evidence'.\n\nReference index:\n[1] 3641289.pdf (2024)\n[2] 2303.18223v16.pdf (2025)\n[3] 0712.3329v1.pdf (2007)\n\nIMPORTANT OUTPUT REQUIREMENTS:\nYour final answer must end with a section titled 'References'.\nList all unique PDFs exactly once in the format:\n[n] FILENAME.pdf (YEAR)\nThis section must be at the end of your output.",
  "retrieved_chunks_raw": [
    {
      "score": 0.5473401546478271,
      "text": ". Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::85dff6bd2fb4",
      "raw_rank": 23,
      "final_score": -1.5411080718040466,
      "relevance": 3,
      "rank": 1
    },
    {
      "score": 0.6127892732620239,
      "text": ". We consistently maintain the related open-source materials at: INTRODUCTION Understanding the essence of intelligence and establishing whether a machine embodies it poses a compelling question for scientists. It is generally agreed upon that authentic intelligence equips us with reasoning capabilities, enables us to test hypotheses, and prepares for future eventualities. . In particular, Artificial Intelligence (AI) researchers focus on the development of machine-based intelligence, as opposed",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::e1d85cdbb466",
      "raw_rank": 2,
      "final_score": -3.2157154977321625,
      "relevance": 3,
      "rank": 2
    },
    {
      "score": 0.4304761290550232,
      "text": ". A significant takeaway from previous attempts is the paramount importance of AI evaluation, which serves as a critical tool to identify current system limitations and inform the design of more powerful models. Recently, large language models (LLMs) have incited substantial interest across both academic and industrial domains. . As demonstrated by existing work, the great performance of LLMs has raised promise that they could be AGI in this era. . LLMs possess the capabilities to solve diverse ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::f744bf595495",
      "raw_rank": 53,
      "final_score": -3.349812760949135,
      "relevance": 3,
      "rank": 3
    },
    {
      "score": 0.5108852386474609,
      "text": ". Abstract—Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine.. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language.",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2303.18223v16.pdf::2025::63f7ecf49d70",
      "raw_rank": 4,
      "final_score": -3.4004303216934204,
      "relevance": 3,
      "rank": 4
    },
    {
      "score": 0.6300026178359985,
      "text": ". In this paper we approach the problem of defining machine intelligence as follows: Section 2 overviews well known theories, definitions and tests of intelligence that have been developed by psychologists. Our objective in this section is to gain an understanding of the essence of intelligence in the broadest possible terms. . In particular we are interested in commonly expressed ideas that could be applied to arbitrary systems and contexts, not just humans. . Section 3 takes these key ideas an",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::b551e995a739",
      "raw_rank": 19,
      "final_score": -3.4316050708293915,
      "relevance": 3,
      "rank": 5
    },
    {
      "score": 0.49513185024261475,
      "text": "As such, trustworthy AI in the context of NLG necessitates understanding the areas where such models may be abused, and how these abuses may be prevented (either with detection technologies, moderation mechanisms, government legislation, or platform policies). When discussing attacks, we discuss not only the direct impact on targets, but also the broader impacts of both attacks and mitigation measures on trust.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::a3adc0e308cc",
      "raw_rank": 29,
      "final_score": -3.8090550005435944
    },
    {
      "score": 0.4321948289871216,
      "text": ". It may be difficult to differentiate those who mean to exploit such systems (e.g., thoughtlessly spam submissions to as many avenues as possible), and those who are relying on AI writing tools to better express themselves.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::7b9fad77ea54",
      "raw_rank": 52,
      "final_score": -3.860286682844162
    },
    {
      "score": 0.5872358679771423,
      "text": ". In the current paper we explore universal intelligence in much greater detail, in particular the way in which it relates to mainstream views on human intelligence and other proposed definitions of machine intelligence. Human intelligence is an enormously rich topic with a complex intellectual, social and political history. . For an overview the interested reader might want to consult \"Handbook of Intelligence\" . [Ste00] edited by R. J. Sternberg. . Our objective in this section is simply to sk",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::175d12dd01ed",
      "raw_rank": 20,
      "final_score": -3.868133917450905
    },
    {
      "score": 0.6319673657417297,
      "text": "In this paper we approach this problem in the following way: We take a number of well known informal definitions of human intelligence that have been given by experts, and extract their essential features. These are then mathematically formalised to produce a general measure of intelligence for arbitrary machines. . We believe that this equation formally captures the concept of machine intelligence in the broadest reasonable sense. . We then show how this formal definition is related to the theo",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::fbf0fc9f1794",
      "raw_rank": 1,
      "final_score": -3.8995459526777267
    },
    {
      "score": 0.4826030433177948,
      "text": "This statement demonstrates that supervised models significantly outperform zero-shot models in terms of performance, highlighting that an increase in parameters does not necessarily guarantee a higher level of social knowledge in this particular scenario.. 3.1.2. Reasoning. The task of reasoning poses significant challenges for an intelligent AI model. . To effectively tackle reasoning tasks, the models need to not only comprehend the provided information but also utilize reasoning and inferenc",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::ecc662314003",
      "raw_rank": 32,
      "final_score": -4.151256687939167
    },
    {
      "score": 0.472107470035553,
      "text": "Third, guided by the EU Ethics Guidelines for Trustworthy AI and research community efforts, we present our survey with sociotechnical and human-centric considerations integrated throughout, focusing not only on NLG systems and machine text detection technologies, but on the humans who will be exposed to both text generation and detection systems in daily life. The goal of trustworthy AI is to ensure that AI systems are developed in ways that are lawful, ethical, and robust both from a technical",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::341f89823db2",
      "raw_rank": 33,
      "final_score": -4.312010392546654
    },
    {
      "score": 0.5741732120513916,
      "text": ". We then examine some of the properties of universal intelligence, such as its ability to sensibly order simple learning algorithms and connections to the theory of universal optimal learning agents.. Section 4 overviews other definitions and tests of machine intelligence that have been proposed. Although surveys of the Turing test and its many variants exist, for example [SCA00], as far as we know this section is the first general survey of definitions and tests of machine intelligence. . Give",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::d93703f6d548",
      "raw_rank": 21,
      "final_score": -4.344935357570648
    },
    {
      "score": 0.4210536479949951,
      "text": "Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. . Considering this rapid technical progress, in this survey, we review the recent advance",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2303.18223v16.pdf::2025::ea3b381a808a",
      "raw_rank": 60,
      "final_score": -4.350452244281769
    },
    {
      "score": 0.44256460666656494,
      "text": ". The SP theory is a new theory of computing and cognition developed with the aim of integrating and simplifying a range of concepts in computing and cognitive science, with a particular emphasis on concepts in artificial intelligence. An overview of the theory is presented in Wolff and more detail may be found in earlier publications cited there. . Amongst other things, the SP theory provides an attractive model for database applications, especially those requiring a measure of human-like 'inte",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::e0c690d03c51",
      "raw_rank": 47,
      "final_score": -4.377718061208725
    },
    {
      "score": 0.4709354043006897,
      "text": "The EU ethics guidelines for trustworthy AI emphasize that unintended or dual-use applications of AI systems should be taken into account, and that steps should be taken to prevent and mitigate abuse of AI systems to cause harm.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::44d5f016167a",
      "raw_rank": 34,
      "final_score": -4.483524903655052
    },
    {
      "score": 0.45923739671707153,
      "text": ". To summarize, the major contributions of this work are as follows: • The most complete survey of machine generated text detection to date, including previously omitted feature-based work and findings from recent contemporary research.. • The first detailed review of the threat models enabled by machine generated text, at a critical juncture where NLG models and tools are rapidly improving and proliferating. . • . A meaningful exploration of both topics through the lens of Trustworthy AI (TAI),",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::f2298e5175a1",
      "raw_rank": 39,
      "final_score": -4.796367928385735
    },
    {
      "score": 0.496239572763443,
      "text": ". We are particularly interested in common themes and general perspectives on intelligence that could be applicable to many kinds of systems, as these will form the foundation of our definition of machine intelligence in the next section.. children. [Bin11]. It was found that Binet's test results were a good predictor of children's academic performance. . Lewis Terman of Stanford",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::ea49dafed84b",
      "raw_rank": 28,
      "final_score": -4.814490579068661
    },
    {
      "score": 0.4100642204284668,
      "text": "Additional Key Words and Phrases: machine learning, artificial intelligence, neural networks, trustworthy AI, machine generated text, transformer, text generation, threat modeling, cybersecurity, disinformation, generative AI Since the release of GPT-2 and subsequent explosion of high-quality Transformer-based NLG models, there has been only one general survey on detection of machine generated text. The scope of this previous survey is constrained to detection methods specifically targeting the ",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::de479b9a4253",
      "raw_rank": 69,
      "final_score": -4.831905245780945
    },
    {
      "score": 0.41693025827407837,
      "text": ". Although these results, in and of themselves, may not ap pear earth-shattering, they do highlight an im portant point: outsiders (i.e., people other than the system's designers) were able to investigate and experimentally validate a knowledge engi neering exercise. This type of experimentation is rare in AI and almost unheard of in knowl edge engineering; it was possible, in large part, because of the transparency of the Bayes net formalism. . Verifiable, reproducible, and controlled ex perime",
      "metadata": {
        "source_file": "1304.1106v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 8,
        "origin_chunk_file": "1304.1106v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1106v1.pdf::1990::6ce03695c520",
      "raw_rank": 14,
      "final_score": -4.987798199057579
    },
    {
      "score": 0.5062556862831116,
      "text": "To measure the intelligence of such diverse systems in a meaningful way we must step back from the specifics of particular systems and establish the underlying fundamentals of what it is that we are really trying to measure. The difficulty of developing an abstract and highly general notion of intelligence is readily apparent. . Consider, for example, the memory and numerical computation tasks that appear in some intelligence tests and which were once regarded as defining hallmarks of human inte",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::78a3ab2819b2",
      "raw_rank": 27,
      "final_score": -5.142799481749535
    },
    {
      "score": 0.5711573362350464,
      "text": ". A fundamental problem in artificial intelligence is that nobody really knows what intelligence is.. The problem is especially acute when we need to consider artificial systems which are significantly different to humans.",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::763164362c30",
      "raw_rank": 22,
      "final_score": -5.185725718736649
    },
    {
      "score": 0.42352771759033203,
      "text": ". Turing's proposed \"imitation game\" in 1950 considered the question of machine intelligence based on the ability of a machine to conduct human-like conversation over a text channel, for which the first widely-published method dates back to 1966 with the ELIZA chatbot.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::4bdab79968a9",
      "raw_rank": 58,
      "final_score": -5.494966745376587
    },
    {
      "score": 0.47623342275619507,
      "text": "It provides a framework for processing that knowledge that integrates and simplifies a range of artificial intelligence functions including probabilistic and exact forms of reasoning, unsupervised learning, fuzzy pattern recognition, best-match information retrieval, planning, problem solving and others. Prototypes of the SP system have been developed as software simulations running on an ordinary computer. . These prototypes serve to demonstrate what can be done with the system and they provide",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::1d8bb9d6b450",
      "raw_rank": 6,
      "final_score": -5.521413341164589
    },
    {
      "score": 0.4517877697944641,
      "text": ". Although it is widely acknowledged that much of human knowledge is uncertain, it is in the field of artificial intelligence that research on the representation and management of uncertainty in rule based reasoning has been focused (Kanal & Lemmer, 1986; Hink & Woods, 1987). Most of the work on uncertainty in artificial intelligence has so far been normative, stressing issues of mathematical correctness and effectiveness. . The approach taken in this paper is not normative, but descriptive. . I",
      "metadata": {
        "source_file": "1304.1083v1.pdf",
        "title": null,
        "authors": null,
        "year": "1989",
        "detected_language": null,
        "page_count": 6,
        "origin_chunk_file": "1304.1083v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1083v1.pdf::1989::e330b10ef834",
      "raw_rank": 10,
      "final_score": -5.668523833155632
    },
    {
      "score": 0.4059852659702301,
      "text": "For example, PSAAM (Steffensen, Dufault-Thompson, and Zhang 2016) is software designed for the curation and analysis of metabolic models, yet a biologist researching metabolism might find it challenging to integrate this analytical method into common data analysis tools like Excel or R. With the rise of generative AI, new opportunities have emerged in statistics and data science. LLM-based data agents are gradually addressing existing challenges while introducing a new paradigm for approaching d",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::3656d6ba434e",
      "raw_rank": 73,
      "final_score": -5.8003169521689415
    },
    {
      "score": 0.40395376086235046,
      "text": "That said, most applications that have been developed to date have a 'declarative' flavour and the ways in which the system may be applied to arithmetic or other mathematical operations have not yet been explored in any depth (but see Wolff ). This has a bearing on how the system may be developed for database applications, as will be discussed in Section 7. . Many problems in artificial intelligence are known to be intractable if one wishes to obtain the best possible answer. . But if one is con",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::fcca44ab2ee4",
      "raw_rank": 75,
      "final_score": -6.224351353943348
    },
    {
      "score": 0.48763877153396606,
      "text": ". The issues that continue to draw debate are the questions such as whether the tests test only a part or a particular type of intelligence, or whether they are somehow biased towards a particular group or set of mental skills. Great effort has gone into dealing with these issues, but they are difficult problems with no easy solutions. . Somewhat disconnected from this exists a parallel debate over the nature of intelligence in the context of machines. . While the debate is less politically char",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::7a353eff6735",
      "raw_rank": 31,
      "final_score": -6.325866147875786
    },
    {
      "score": 0.45015817880630493,
      "text": ". Expert systems have emerged around mid-1970s under the umbrella of Artificial Intelligence and as soon as convincing success was attained, the field was transformed into an established branch of computer science. The potential of expert systems that emulate human knowledge and skill has also encouraged the development of many applications in various areas. . Expert systems contain specialized knowledge elicited from a domain expert. . Various expert system building tools or shells exist to gre",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::1f0818e4c126",
      "raw_rank": 42,
      "final_score": -6.339300379157066
    },
    {
      "score": 0.49361133575439453,
      "text": "2.1 Definition and Scope In this survey, we use a broad definition of the term \"machine generated text\" which we believe includes all relevant research in the field: We focus our definition of machine generated text on natural language — i.e., text written in human languages that are \"acquired naturally (in [an] operationally defined sense) in association with speech\" — and exclude non-natural language — i.e., logical languages, programming languages, etc. Exclusion of non-natural language align",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::bd1a671a542c",
      "raw_rank": 30,
      "final_score": -6.351754426956177
    },
    {
      "score": 0.509662389755249,
      "text": ". (1) Identify the system under attack: We provide a broad attack-centric analysis of machine generated text on society, rather than a system-centric analysis focusing on vulnerabilities to a specific IT system. As such, we identify several discrete technological systems, within the broader societal supersystem.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::97b789622b90",
      "raw_rank": 26,
      "final_score": -6.3885326981544495
    },
    {
      "score": 0.4269382357597351,
      "text": ". The developers of expert systems and decision support systems have long been aware of the importance of facilities to explain the computer based reasoning to users as a prerequisite to their more widespread acceptance (e.g. Teach & Shortliffe, 1981).. Unless users can come to * This work was supported by the National Science Foundation under grant IRI-<PHONE> to Carnegie Mellon and by the Rockwell International Science Center. . understand the assumptions and reasoning of such systems, it is i",
      "metadata": {
        "source_file": "1304.1082v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "1304.1082v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1082v1.pdf::1990::40911c1531a3",
      "raw_rank": 55,
      "final_score": -6.539799407124519
    },
    {
      "score": 0.46727627515792847,
      "text": ". In some cases, a machine may display properties that we equate with human intelligence, in such cases it might be \"Innumerable tests are available for measuring intelligence, yet no one is quite certain of what intelligence is, or even just what it is that the available tests are measuring.\" — R. L. Gregory . [Gre98] reasonable to describe the machine as also being intelligent. . In other situations this view is far too limited and anthropocentric.",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::d52f5669b2e8",
      "raw_rank": 35,
      "final_score": -6.650912836194038
    },
    {
      "score": 0.4231914281845093,
      "text": ". Since our goal is to produce interpretations of probabilistic reasoning that are more compatible with human reasoning styles, we started out with an empirical study of human strategies for uncertain reasoning. This provided us with the inspiration for the design of two new and contrasting modes of explaining probabilistic reasoning, namely qualitative belief propagation and scenario-based reasoning. . It is useful to distinguish explanation as the communication of static knowledge or beliefs f",
      "metadata": {
        "source_file": "1304.1082v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "1304.1082v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1082v1.pdf::1990::f5d99a04d2d3",
      "raw_rank": 59,
      "final_score": -6.703410297632217
    },
    {
      "score": 0.4659643769264221,
      "text": ". As previously mentioned, NLG encompasses a large variety of tasks and research areas, with this brief section serving as context for understanding machine generated text threat models and detection methods.. 2.3.1 Non-Neural Models. Predating the popularization of neural approaches in the NLG domain, a range of systems were used to accomplish NLG tasks. . These early approaches can broadly be summarized as \"rule-based\", though there existed variety in terms of processes, pipelines, and targets",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::6469aa988ef2",
      "raw_rank": 36,
      "final_score": -6.703904375433922
    },
    {
      "score": 0.42680296301841736,
      "text": ". MACHINE GENERATED TEXT Before reviewing threat models and detection methodologies for machine generated text, it is helpful to briefly provide a formal definition of machine generated text, and a condensed overview of natural language generation (NLG) models. We recommend further reading of dedicated surveys on natural language generation for greater insight into the wide breadth of NLG models and applications.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::e03808f04a5d",
      "raw_rank": 56,
      "final_score": -6.709542669355869
    },
    {
      "score": 0.4596342444419861,
      "text": ". (4) Review whether the analysis is accurate and complete: We have given careful thought to the presented threat models, which are formed from perspectives gained across industry, academia, and government. However, as threat modeling is an iterative process that benefits from diverse perspectives, we greatly encourage further analysis of potential attacks and mitigation measures in future research. . The remainder of this section comprises our threat model analysis, grouped according to a break",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::3b6079b09c89",
      "raw_rank": 38,
      "final_score": -6.732670918107033
    },
    {
      "score": 0.41017386317253113,
      "text": ". Another method involves the Retrieval-Augmented Generation (RAG) technique (Lewis et al. 2020), where relevant code is first retrieved and then embedded within the context to facilitate incontext learning. LLM-based agents can also access and interact with external knowledge sources, such as databases or knowledge graphs, to augment their reasoning capabilities (Wang et al. 2024b). . Sun et al. proposes a Knowledge Integration method that builds on this concept. . In LAMBDA, analysis codes are",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::172c5daf9044",
      "raw_rank": 68,
      "final_score": -6.775890715420246
    },
    {
      "score": 0.4287664294242859,
      "text": ". Comprehensible explanations of probabilistic reasoning are a prerequisite for wider acceptance of Bayesian methods in expert systems and decision support systems.",
      "metadata": {
        "source_file": "1304.1082v1.pdf",
        "title": null,
        "authors": null,
        "year": "1990",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "1304.1082v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1082v1.pdf::1990::132a9876fb38",
      "raw_rank": 13,
      "final_score": -6.778885796666145
    },
    {
      "score": 0.44948646426200867,
      "text": ". Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the 'where' and 'how' questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. . Then, we summarize the success and failure cases of LLMs in different tasks. ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::c59652d07ccb",
      "raw_rank": 43,
      "final_score": -6.782790966331959
    },
    {
      "score": 0.45468011498451233,
      "text": "Approach 2.1 Model and Architectures......................................... 2.2 Training Dataset.............................................. 2.3 Training Process............................................. 2.4 Evaluation................................................. Results 3.1 Language Modeling, Cloze, and Completion Tasks........................... 3.2 Closed Book Question Answering.................................... 3.3 Translation................................................ 3.4 ",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2005.14165v4.pdf::2020::b18961a6fe8c",
      "raw_rank": 8,
      "final_score": -6.809828124940395
    },
    {
      "score": 0.4805692434310913,
      "text": ". The general architecture of an expert system is presented in Figure 1 and its components are defined as follows (1): • User interface—the mechanism by which the user and the expert system communicate.. • Explanation facility—explains the reasoning of the system to a user. • Working memory—a database of facts used by the rules. . • Inference engine—makes inferences by deciding which rules are satisfied by facts or objects, prioritizes the satisfied rules, and executes the rule with the highest ",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::9aef20ca04a4",
      "raw_rank": 5,
      "final_score": -6.844846397638321
    },
    {
      "score": 0.4281689524650574,
      "text": ". Ideally we would like to be able to measure the intelligence of a wide range of systems; humans, dogs, flies, robots or even disembodied systems such as chat-bots, expert systems, classification systems and prediction algorithms. [Joh92, Alb91]. One response to this problem might be to develop specific kinds of tests for specific kinds of entities; just as intelligence tests for children differ to intelligence tests for adults.",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::eb91400b289b",
      "raw_rank": 54,
      "final_score": -6.860587194561958
    },
    {
      "score": 0.4578493535518646,
      "text": ". Although more work is required in understanding how the model may be developed for learning, other aspects are sufficiently robust and mature for development into an industrial strength working system.. I am grateful to Thomas Connolly for constructive comments on this article. The responsibility for all errors and oversights is, of course, my own. . M. Abdelguerfiand S. Lavington, editors. . Emerging Trends in Database and Knowledge-base Machines: The Application of Parallel Architectures to ",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::62810bd2dcad",
      "raw_rank": 40,
      "final_score": -6.876822032034397
    },
    {
      "score": 0.4256379306316376,
      "text": ". Before presenting the results from our large-scale empirical study, we review the necessary background topics required to understand our results, including the Transformer model architecture and the downstream tasks we evaluate on.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1910.10683v4.pdf::2023::ff7415cced87",
      "raw_rank": 57,
      "final_score": -6.9602664187550545
    },
    {
      "score": 0.4419177174568176,
      "text": ". The SP system should be able to organise its knowledge automatically in a way that minimises redundancies and reveals the natural structures in that knowledge, including class hierarchies, part-whole hierarchies and their integration. It should also be able to abstract rules and other generalisations from its stored knowledge, in the manner of datamining systems. . Of course, existing datamining techniques may also be applied to an SP database. . It would take us too far afield to attempt a de",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::367243e3eebc",
      "raw_rank": 48,
      "final_score": -6.9824148863554
    },
    {
      "score": 0.45241880416870117,
      "text": "Specifically, we define an LLM-based data agent as an autonomous or semi-autonomous software system powered by LLMs, capable of understanding natural language instructions, planning and executing data-centric tasks, and interacting with users or external tools to accomplish complex objectivesfrom exploratory data analysis to machine learning model development. In this article, the terms \"LLM-based data science agent,\" \"LLM-based data agent,\" and \"data science agent\" are collectively referred to ",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::4701f38dbb41",
      "raw_rank": 9,
      "final_score": -7.007083058357239
    },
    {
      "score": 0.44654983282089233,
      "text": ". After expert systems have moved out of research laboratories during early 1980s, they became more popular and found several application fields such as engineering, chemistry, medicine, industry, and many others. The construction process of expert systems with specialized domain knowledge is defined as knowledge engineering. . Knowledge-based expert systems contain knowledge acquired from periodicals, books, or from domain interviews with human experts. . Expert systems are mostly preferred as ",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::bab1f1e7ac80",
      "raw_rank": 44,
      "final_score": -7.048875704407692
    },
    {
      "score": 0.4094845950603485,
      "text": ". The most that ordinary reasoners can realistically be expected to know, at least implicitly, is how certain they are of various instantiated antecedent conditions and the maximum certainty factors contained in the conclusions of their production rules. Any of the various normative models of reasoning under uncertainty could be candidates for descriptive models of how ordinary people reason. . Some of these candidates could conceivably be ruled out as psychological models in terms of the amount",
      "metadata": {
        "source_file": "1304.1083v1.pdf",
        "title": null,
        "authors": null,
        "year": "1989",
        "detected_language": null,
        "page_count": 6,
        "origin_chunk_file": "1304.1083v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1304.1083v1.pdf::1989::ffefa69c12a2",
      "raw_rank": 70,
      "final_score": -7.078220672905445
    },
    {
      "score": 0.4115111231803894,
      "text": "For decades, con structing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a fea ture extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Deep learning is making major advances in solving problems that have resisted the best attempts of t",
      "metadata": {
        "source_file": "NatureDeepReview.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 9,
        "origin_chunk_file": "NatureDeepReview.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "NatureDeepReview.pdf::2025::3e333976691b",
      "raw_rank": 15,
      "final_score": -7.0793963223695755
    },
    {
      "score": 0.41672059893608093,
      "text": ". Building an ES is an iterative process involving the creation of a prototype system and then over a number of cycles of testing, repair, and extension, incrementally improving the system so that it eventually performs in a way that is satisfactory and beneficial to the users. The problem identification, conceptualization, formalization, construction, and testing are the stages of ES development process (4). . Once a system has been built and debugged it is a simple matter to extend its coverag",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::0d59c63e3fa6",
      "raw_rank": 63,
      "final_score": -7.088669009506702
    },
    {
      "score": 0.40529298782348633,
      "text": "While data agents are generally robust to variations in prompt phrasing and can reliably complete the intended analytical tasks, we observed notable differences in their reasoning processes and implementation details.",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::2b685750375b",
      "raw_rank": 74,
      "final_score": -7.114532828330994
    },
    {
      "score": 0.4346300959587097,
      "text": "Given the large volume of NLG research over the past 55 years, we provide only a high-level taxonomy of major NLG tasks and approaches as groundwork for our analysis of threat models and detection methodologies, and leave detailed discussion to aforementioned dedicated surveys. 2.2.1 Natural Language Generation Tasks. . Recall from §1.1 that there are a wide variety of applications for natural language generation. . Leveraging previous surveys, we provide a summary of major tasks in the NLG doma",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::ffcd44c2b323",
      "raw_rank": 49,
      "final_score": -7.125428274273872
    },
    {
      "score": 0.40641969442367554,
      "text": ". To understand the risks that motivate research on detection of machine generated text, we draw from existing literature to present a series of threat models incorporating natural language generation. Threat modeling reflects the process of thinking like an attacker, identifying vulnerabilities to systems by identifying potential attackers, their capabilities, and objectives. . The goal of threat modeling is to improve the security of systems by considering the greatest threats to systems and t",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::3570e19720bc",
      "raw_rank": 72,
      "final_score": -7.206494823098183
    },
    {
      "score": 0.5164794921875,
      "text": ". CCS Concepts: • Computing methodologies →Machine learning approaches; Neural networks; Natural language generation; • Security and privacy →Human and societal aspects of security and privacy.",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::b19c863e302e",
      "raw_rank": 24,
      "final_score": -7.2207887172698975
    },
    {
      "score": 0.4447898268699646,
      "text": "We explore current trends in the design of LLM-based frameworks, detailing essential features such as planning, reasoning, reflection, multi-agent collaboration, user interface, knowledge integration, and system design, which enable agents to address data-centric problems with minimal human intervention. Furthermore, we analyze several case studies to demonstrate the practical applications of various data agents in realworld scenarios. . Finally, we identify key challenges and propose future res",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::03120c6c5d13",
      "raw_rank": 46,
      "final_score": -7.235486760735512
    },
    {
      "score": 0.4415018558502197,
      "text": "The rapid rate of progress and diversity of techniques in this burgeoning field can make it difficult to compare different algorithms, tease apart the effects of new contributions, and understand the space of existing methods for transfer learning.",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1910.10683v4.pdf::2023::a7d0f7cc72f9",
      "raw_rank": 11,
      "final_score": -7.27915757894516
    },
    {
      "score": 0.41054803133010864,
      "text": ". By providing an intuitive interface that harnesses the capabilities of LLMs, users can request analyses using natural language, and the data agents can interpret these instructions, access relevant data, and autonomously apply appropriate analytical techniques. For example, a user might request, \"Calculate the sales growth in different regions from 2021 to 2028, generate a bar chart to visualize the results, and provide key insights.\"",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::308f19ff4e9c",
      "raw_rank": 67,
      "final_score": -7.3280332535505295
    },
    {
      "score": 0.43428683280944824,
      "text": ". Knowledge-based expert systems will continue to increase individual and social potential by preserving know-how, distributing knowledge more effectively, and improving performance of tasks that require expertise. 24. I. M. Dokas and A. Alapetite, A Development Process Meta-Model for Web Based Expert Systems: The Web Engineering Point of View, Risø National Laboratory, Denmark, 2006. . 25. . R. Islam and K. Andersson, Mohammad Shahadat Hossain, A Web Based Belief Rule Based Expert System to Pre",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::3f868e4f3792",
      "raw_rank": 50,
      "final_score": -7.343091309070587
    },
    {
      "score": 0.412870317697525,
      "text": ". LAMBDA facilitates an interactive analysis process, enabling us to perform tasks such as data processing, feature engineering, model training, parameter tuning, and evaluation through a series of guided conversations. Finally, we used LAMBDA's built-in report generation feature to compile a analysis report, which includes details of the tasks completed in the conversation history. . The analysis process, including the conversation and the generated report, is presented in Figure 6. . As beginn",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::f38b966bb5f1",
      "raw_rank": 65,
      "final_score": -7.354178927838802
    },
    {
      "score": 0.4609013497829437,
      "text": ". Where the full versatility of this scheme is not needed, it is also possible to create networks and hierarchies from patterns like '... ', '... ' and '... ' that can be linked end-to-end by alignment within a multiple alignment. This section briefly reviews aspects of intelligence that have been shown to fall within the scope of the SP system, highlighting those with particular relevance to intelligent databases. . The main points of difference between the SP system and other artificial intell",
      "metadata": {
        "source_file": "0311031v1.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 25,
        "origin_chunk_file": "0311031v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0311031v1.pdf::2018::24ea58fd4673",
      "raw_rank": 37,
      "final_score": -7.399413801729679
    },
    {
      "score": 0.5164233446121216,
      "text": ". (2) Regarding what to evaluate, we summarize existing tasks in various areas and obtain insightful conclusions on the success and failure case of LLMs (Section 6), providing experience for future research. (3) As for where to evaluate, we summarize evaluation metrics, datasets, and benchmarks to provide a profound understanding of current LLMs evaluations. . In terms of how to evaluate, we explore current protocols and summarize novel evaluation approaches. . (4) We further discuss future chal",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::0247478323b2",
      "raw_rank": 25,
      "final_score": -7.462833136320114
    },
    {
      "score": 0.5224646329879761,
      "text": "3.1 Threat Modeling Fundamentals As we anticipate an audience with varying exposure to cybersecurity topics, before we present threat models related to machine generated text, it is helpful to first provide an overview of threat modeling, and characterize the approach taken in this section. A basic example of a common threat model is \"a thief who wants to steal your money\". . We can add detail to this threat model by considering more specific capabilities and objectives that such an attacker mig",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::9de497dca2cc",
      "raw_rank": 3,
      "final_score": -7.46482327580452
    },
    {
      "score": 0.40834471583366394,
      "text": ". Julius (Julius 2025) facilitates data science education by building a bridge that allowing professors to create interactive workflows for lessons, which can be shared with students for a seamless teaching experience through natural language interaction. In this section, we present a series of case studies conducted by a diverse range of agents, each illustrating the new data analysis paradigm facilitated through natural language interaction. . These case studies demonstrate how this approach e",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::d66fb2582f37",
      "raw_rank": 71,
      "final_score": -7.519311316311359
    },
    {
      "score": 0.37848013639450073,
      "text": "As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial taskspecific architecture modifications. BERT is conceptually simple and empirically powerful.",
      "metadata": {
        "source_file": "1810.04805v2.pdf",
        "title": null,
        "authors": null,
        "year": "2019",
        "detected_language": null,
        "page_count": 16,
        "origin_chunk_file": "1810.04805v2.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1810.04805v2.pdf::2019::c7df14115f1b",
      "raw_rank": 18,
      "final_score": -7.57467956840992
    },
    {
      "score": 0.4107818305492401,
      "text": ". Conversational methods support interactive dialogue with iterative user feedback, whereas End-to-End approaches rely on a single prompt, with the agent autonomously planning and solving the problem.. The user interface can be categorized into IDEbased, Systems, CLI, and OS-based.",
      "metadata": {
        "source_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "A Survey on Large Language Model-based Agents for Statistics and Data Science.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "A Survey on Large Language Model-based Agents for Statistics and Data Science.pdf::2025::fcce64a80b95",
      "raw_rank": 66,
      "final_score": -7.629492290318012
    },
    {
      "score": 0.38273805379867554,
      "text": ". Our baseline, the ESIM sequence model from Chen et al., uses a biLSTM to encode the premise and hypothesis, followed by a matrix attention layer, a local inference layer, another biLSTM inference composition layer, and finally a pooling operation before the output layer. Overall, adding ELMo to the ESIM model improves accuracy by an average of 0.7% across five random seeds. . A five member ensemble pushes the overall accuracy to 89.3%, exceeding the previous ensemble best of 88.9%. . Semantic ",
      "metadata": {
        "source_file": "N18-1202.pdf",
        "title": null,
        "authors": null,
        "year": "2018",
        "detected_language": null,
        "page_count": 11,
        "origin_chunk_file": "N18-1202.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "N18-1202.pdf::2018::b65019079157",
      "raw_rank": 16,
      "final_score": -7.721857562661171
    },
    {
      "score": 0.44495439529418945,
      "text": "Finally, given the broad spectrum of capabilities displayed by GPT-3, we discuss concerns about bias, fairness, and broader societal impacts, and attempt a preliminary analysis of GPT-3's characteristics in this regard.. The remainder of this paper is organized as follows. In Section 2, we describe our approach and methods for training GPT-3 and evaluating it. . Section 3 presents results on the full range of tasks in the zero-, one- and few-shot settings. . Section 4 addresses questions of data",
      "metadata": {
        "source_file": "2005.14165v4.pdf",
        "title": null,
        "authors": null,
        "year": "2020",
        "detected_language": null,
        "page_count": 75,
        "origin_chunk_file": "2005.14165v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2005.14165v4.pdf::2020::e2981918a7fc",
      "raw_rank": 45,
      "final_score": -7.740527033805847
    },
    {
      "score": 0.41888687014579773,
      "text": "Recognizing that the main utility of transfer learning is the possibility of leveraging pre-trained models in data-scarce settings, we release our code, data sets, and pre-trained models.1 The remainder of the paper is structured as follows: In the following section, we discuss our base model and its implementation, our procedure for formulating every text processing problem as a text-to-text task, and the suite of tasks we consider. In Section 3, we present a large set of experiments that explo",
      "metadata": {
        "source_file": "1910.10683v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 67,
        "origin_chunk_file": "1910.10683v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1910.10683v4.pdf::2023::c0ffaec5863c",
      "raw_rank": 62,
      "final_score": -7.772763080894947
    },
    {
      "score": 0.4325219988822937,
      "text": ". For the query-focused summarization task, Pasunuru et al. used a search engine, i.e., Bing, to retrieve the answer paragraph as the synthetic summary and used the top ranked documents as input text.. Another line of work is to use perturbation-based methods by corrupting the original text. For example, Chen et al. presented a set of data augmentation methods for conversation summarization, such as random swapping/deletion to randomly swap or delete utterances in conversations. . Multi-Task Lea",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2201.05273v4.pdf::2022::7e185834e6cc",
      "raw_rank": 51,
      "final_score": -7.814508393406868
    },
    {
      "score": 0.45972156524658203,
      "text": "We begin with introducing three key aspects of applying PLMs to text generation: 1) how to encode the input into representations preserving input semantics which can be fused into PLMs; 2) how to design an effective PLM to serve as the generation model; and 3) how to effectively optimize PLMs given the reference text and to ensure that the generated texts satisfy special text properties. Then, we show the major challenges arisen in these aspects, as well as possible solutions for them. . We also",
      "metadata": {
        "source_file": "2201.05273v4.pdf",
        "title": null,
        "authors": null,
        "year": "2022",
        "detected_language": null,
        "page_count": 35,
        "origin_chunk_file": "2201.05273v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2201.05273v4.pdf::2022::b45e7569ccf5",
      "raw_rank": 7,
      "final_score": -7.88854455947876
    },
    {
      "score": 0.42087656259536743,
      "text": "The neural network consists of cells that correspond to symptoms in the input layer, the diseases are presented in the intermediate or hidden layer and neural cells (nodes) for the treatments defined in the output layer. Training patterns consist of 0's (lack of knowledge about presence or absence of the disease), 1's (presence of the disease), and 1's (absence of the disease). . A sample rule from Hepar, a medical expert system for the diagnosis of liver and biliary tract diseases is (16) . The",
      "metadata": {
        "source_file": "Expert_Systems.pdf",
        "title": null,
        "authors": null,
        "year": "2016",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "Expert_Systems.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "Expert_Systems.pdf::2016::5bf9e2d582d7",
      "raw_rank": 61,
      "final_score": -7.942326292395592
    },
    {
      "score": 0.45376506447792053,
      "text": ". (2) Determine potential attackers, their capabilities, and objectives: We consider threat actors of varying sophistication and motives, but with a common modus operandi — in all cases, our attacker is an individual or organization exploiting an NLG model. We characterize the attacker when explaining each attack. . (3) Devise a mitigation strategy: After identifying a threat model, we propose mitigation measures to improve security and reduce risk. . Detection of computer-generated text is ofte",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::7ac846fb14ba",
      "raw_rank": 41,
      "final_score": -7.947430811822414
    },
    {
      "score": 0.4162963330745697,
      "text": ". Machine generated text detection should then be used among multiple features, such as account creation times, activity patterns, registered phone numbers, and IP addresses, to determine whether activity is linked together as part of an online influence operation. 3.4.2 Applications and Cover Letters. . Contemporary NLG models can be used to generate large numbers of cover letters or essays for applying for scholarships or to employment opportunities. . Commercial websites already exist for pro",
      "metadata": {
        "source_file": "2210.07321v4.pdf",
        "title": null,
        "authors": null,
        "year": "2023",
        "detected_language": null,
        "page_count": 36,
        "origin_chunk_file": "2210.07321v4.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2210.07321v4.pdf::2023::85c51e273261",
      "raw_rank": 64,
      "final_score": -8.038353599607944
    },
    {
      "score": 0.43524497747421265,
      "text": ". Opened just last week, with the help of National Museums of Scotland funds and a gaggle of sponsors, the gallery at the Royal Museum offers a wealth of interactive, visually-stunning and unique displays.... The exhibition space has been divided into five main subject areas covering transport (Move It!), artificial intelligence (Robots), cloning (Me2), space travel (Blast Off!) and energy (Power Up). . Each subject area is designed around a number of significant museum objects, complemented by ",
      "metadata": {
        "source_file": "1887-Article Text-1883-1-10-20080129.pdf",
        "title": null,
        "authors": null,
        "year": "2006",
        "detected_language": null,
        "page_count": 1,
        "origin_chunk_file": "1887-Article Text-1883-1-10-20080129.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1887-Article Text-1883-1-10-20080129.pdf::2006::fa88a06ed47a",
      "raw_rank": 12,
      "final_score": -8.133512631058693
    },
    {
      "score": 0.3802972137928009,
      "text": ". Lukasz and Aidan spent countless long days designing various parts of and implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating our research.. †Work performed while at Google Brain.. ‡Work performed while at Google Research.",
      "metadata": {
        "source_file": "1706.03762v7.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 15,
        "origin_chunk_file": "1706.03762v7.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "1706.03762v7.pdf::2024::07acaae2dd7c",
      "raw_rank": 17,
      "final_score": -8.177019946277142
    }
  ],
  "retrieved_chunks_final": [
    {
      "score": 0.5473401546478271,
      "text": ". Within the scope of AI, the Turing Test, a widely recognized test for assessing intelligence by discerning if responses are of human or machine origin, has been a longstanding objective in AI evolution. It is generally believed among researchers that a computing machine that successfully passes the Turing Test can be considered as intelligent. . Consequently, when viewed from a wider lens, the chronicle of AI can be depicted as the timeline of creation and evaluation of intelligent models and ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::85dff6bd2fb4",
      "raw_rank": 23,
      "final_score": -1.5411080718040466,
      "relevance": 3,
      "rank": 1
    },
    {
      "score": 0.6127892732620239,
      "text": ". We consistently maintain the related open-source materials at: INTRODUCTION Understanding the essence of intelligence and establishing whether a machine embodies it poses a compelling question for scientists. It is generally agreed upon that authentic intelligence equips us with reasoning capabilities, enables us to test hypotheses, and prepares for future eventualities. . In particular, Artificial Intelligence (AI) researchers focus on the development of machine-based intelligence, as opposed",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::e1d85cdbb466",
      "raw_rank": 2,
      "final_score": -3.2157154977321625,
      "relevance": 3,
      "rank": 2
    },
    {
      "score": 0.4304761290550232,
      "text": ". A significant takeaway from previous attempts is the paramount importance of AI evaluation, which serves as a critical tool to identify current system limitations and inform the design of more powerful models. Recently, large language models (LLMs) have incited substantial interest across both academic and industrial domains. . As demonstrated by existing work, the great performance of LLMs has raised promise that they could be AGI in this era. . LLMs possess the capabilities to solve diverse ",
      "metadata": {
        "source_file": "3641289.pdf",
        "title": null,
        "authors": null,
        "year": "2024",
        "detected_language": null,
        "page_count": 45,
        "origin_chunk_file": "3641289.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "3641289.pdf::2024::f744bf595495",
      "raw_rank": 53,
      "final_score": -3.349812760949135,
      "relevance": 3,
      "rank": 3
    },
    {
      "score": 0.5108852386474609,
      "text": ". Abstract—Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine.. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language.",
      "metadata": {
        "source_file": "2303.18223v16.pdf",
        "title": null,
        "authors": null,
        "year": "2025",
        "detected_language": null,
        "page_count": 144,
        "origin_chunk_file": "2303.18223v16.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "2303.18223v16.pdf::2025::63f7ecf49d70",
      "raw_rank": 4,
      "final_score": -3.4004303216934204,
      "relevance": 3,
      "rank": 4
    },
    {
      "score": 0.6300026178359985,
      "text": ". In this paper we approach the problem of defining machine intelligence as follows: Section 2 overviews well known theories, definitions and tests of intelligence that have been developed by psychologists. Our objective in this section is to gain an understanding of the essence of intelligence in the broadest possible terms. . In particular we are interested in commonly expressed ideas that could be applied to arbitrary systems and contexts, not just humans. . Section 3 takes these key ideas an",
      "metadata": {
        "source_file": "0712.3329v1.pdf",
        "title": null,
        "authors": null,
        "year": "2007",
        "detected_language": null,
        "page_count": 49,
        "origin_chunk_file": "0712.3329v1.chunks.json"
      },
      "query": "Define provide a rigorous definition of ai using only the provided context., describe its theoretical foundations, and explain how definitions evolved historically across publications.",
      "id": "0712.3329v1.pdf::2007::b551e995a739",
      "raw_rank": 19,
      "final_score": -3.4316050708293915,
      "relevance": 3,
      "rank": 5
    }
  ],
  "model_output": "Artificial Intelligence (AI) is a field focused on developing machine-based intelligence that can mimic and, to some extent, surpass human intelligence. [1], [3] The Turing Test serves as a benchmark for evaluating AI by distinguishing between responses from humans and machines. A machine passing the Turing Test can be considered intelligent. [1]\n\nTheoretical foundations of AI are rooted in understanding the essence of intelligence, which includes reasoning capabilities, hypothesis testing, and preparation for future eventualities. Authentic intelligence equips us with these abilities. [1], [3]\n\nOver the years, the definition of AI has evolved to accommodate various perspectives. [3] Initially, the focus was on language comprehension due to the complexity of human expressions governed by grammatical rules. [2] However, current research also includes the development and evaluation of large language models (LLMs), which show great promise in performing a wide range of tasks. [1]\n\nReferences:\n[1] 3641289.pdf (2024)\n[2] 2303.18223v16.pdf (2025)\n[3] 0712.3329v1.pdf (2007)"
}